{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d097ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from collections import defaultdict\n",
    "from Levenshtein import distance\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn import metrics\n",
    "#from sklearn.metrics.cluster import homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score, adjusted_mutual_info_score, silhouette_score\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d563964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\la1949\\Anaconda3\\envs\\pm4py\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "parsing log, completed traces :: 100%|██████████| 4348/4348 [00:38<00:00, 112.78it/s]\n"
     ]
    }
   ],
   "source": [
    "log = pm4py.read.read_xes(\"wabo_all.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cedf6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'tabName_element' column\n",
    "log['activity'] = le.fit_transform(log['taskName'])\n",
    "log_select = log[['case:concept:name', 'time:timestamp', 'activity', 'case:sublog']]\n",
    "log_select2 = log_select.sort_values(by='time:timestamp',ascending=False)\n",
    "log_select_new = log_select2.drop_duplicates(subset=['case:concept:name'])\n",
    "log_select_new = log_select_new.sort_values(by='case:concept:name',ascending=True)\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "logVar = log_select2.groupby(['case:concept:name'])['activity'].apply(list).reset_index()\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "#Add clusters to data frame\n",
    "log_select_new = log_select_new.drop([\"time:timestamp\", \"activity\"], axis=1)\n",
    "logVarClusters = pd.merge(logVar, log_select_new, on=\"case:concept:name\")\n",
    "\n",
    "logVarClusters['caseID'] = le.fit_transform(logVarClusters['case:concept:name'])\n",
    "#logVarClusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a001b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "logVarClusters['label'] = le.fit_transform(logVarClusters['case:sublog'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80fbc2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 2, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVarClusters['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2585f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>activity</th>\n",
       "      <th>case:sublog</th>\n",
       "      <th>caseID</th>\n",
       "      <th>label</th>\n",
       "      <th>act_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10358444</td>\n",
       "      <td>[343, 236, 366, 260, 357, 366, 260, 357, 74, 2...</td>\n",
       "      <td>/usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[343, 236, 366, 260, 357, 366, 260, 357, 74, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11269753</td>\n",
       "      <td>[343, 366, 366, 260, 260, 357, 357, 445, 201, ...</td>\n",
       "      <td>/usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[343, 366, 366, 260, 260, 357, 357, 445, 201, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11666570</td>\n",
       "      <td>[445, 197, 196, 380, 341, 395, 170, 99, 332, 4...</td>\n",
       "      <td>/usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[445, 197, 196, 380, 341, 395, 170, 99, 332, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12421232</td>\n",
       "      <td>[208, 260, 28, 199, 357, 204, 5, 141, 164, 212...</td>\n",
       "      <td>/usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[208, 260, 28, 199, 357, 204, 5, 141, 164, 212...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12592056</td>\n",
       "      <td>[208, 28, 260, 199, 70, 357, 204, 12, 72, 164,...</td>\n",
       "      <td>/usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[208, 28, 260, 199, 70, 357, 204, 12, 72, 164,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>9987434</td>\n",
       "      <td>[21, 158, 431, 322, 376, 153, 425, 426, 404, 9...</td>\n",
       "      <td>/usr/share/eventlogs/12714542/CoSeLoG WABO 5.xes</td>\n",
       "      <td>4341</td>\n",
       "      <td>2</td>\n",
       "      <td>[21, 158, 431, 322, 376, 153, 425, 426, 404, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>9988302</td>\n",
       "      <td>[271, 158, 404, 153, 21, 93, 296, 426, 425, 338]</td>\n",
       "      <td>/usr/share/eventlogs/12714542/CoSeLoG WABO 5.xes</td>\n",
       "      <td>4342</td>\n",
       "      <td>2</td>\n",
       "      <td>[271, 158, 404, 153, 21, 93, 296, 426, 425, 338]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>9989988</td>\n",
       "      <td>[271, 153, 425, 426, 21, 93, 296, 338, 158, 404]</td>\n",
       "      <td>/usr/share/eventlogs/12714542/CoSeLoG WABO 5.xes</td>\n",
       "      <td>4343</td>\n",
       "      <td>2</td>\n",
       "      <td>[271, 153, 425, 426, 21, 93, 296, 338, 158, 404]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>9990823</td>\n",
       "      <td>[442, 321, 104, 20, 319, 34, 60, 5, 212, 164, ...</td>\n",
       "      <td>/usr/share/eventlogs/12714542/CoSeLoG WABO 5.xes</td>\n",
       "      <td>4344</td>\n",
       "      <td>2</td>\n",
       "      <td>[442, 321, 104, 20, 319, 34, 60, 5, 212, 164, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>9998898</td>\n",
       "      <td>[93, 404, 431, 21, 158, 296, 426, 322, 376, 15...</td>\n",
       "      <td>/usr/share/eventlogs/12714542/CoSeLoG WABO 5.xes</td>\n",
       "      <td>4345</td>\n",
       "      <td>2</td>\n",
       "      <td>[93, 404, 431, 21, 158, 296, 426, 322, 376, 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4290 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     case:concept:name                                           activity  \\\n",
       "0             10358444  [343, 236, 366, 260, 357, 366, 260, 357, 74, 2...   \n",
       "1             11269753  [343, 366, 366, 260, 260, 357, 357, 445, 201, ...   \n",
       "2             11666570  [445, 197, 196, 380, 341, 395, 170, 99, 332, 4...   \n",
       "3             12421232  [208, 260, 28, 199, 357, 204, 5, 141, 164, 212...   \n",
       "4             12592056  [208, 28, 260, 199, 70, 357, 204, 12, 72, 164,...   \n",
       "...                ...                                                ...   \n",
       "4285           9987434  [21, 158, 431, 322, 376, 153, 425, 426, 404, 9...   \n",
       "4286           9988302   [271, 158, 404, 153, 21, 93, 296, 426, 425, 338]   \n",
       "4287           9989988   [271, 153, 425, 426, 21, 93, 296, 338, 158, 404]   \n",
       "4288           9990823  [442, 321, 104, 20, 319, 34, 60, 5, 212, 164, ...   \n",
       "4289           9998898  [93, 404, 431, 21, 158, 296, 426, 322, 376, 15...   \n",
       "\n",
       "                                           case:sublog  caseID  label  \\\n",
       "0     /usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes       0      0   \n",
       "1     /usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes       1      0   \n",
       "2     /usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes       2      0   \n",
       "3     /usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes       3      0   \n",
       "4     /usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes       4      0   \n",
       "...                                                ...     ...    ...   \n",
       "4285  /usr/share/eventlogs/12714542/CoSeLoG WABO 5.xes    4341      2   \n",
       "4286  /usr/share/eventlogs/12714542/CoSeLoG WABO 5.xes    4342      2   \n",
       "4287  /usr/share/eventlogs/12714542/CoSeLoG WABO 5.xes    4343      2   \n",
       "4288  /usr/share/eventlogs/12714542/CoSeLoG WABO 5.xes    4344      2   \n",
       "4289  /usr/share/eventlogs/12714542/CoSeLoG WABO 5.xes    4345      2   \n",
       "\n",
       "                                                act_str  \n",
       "0     [343, 236, 366, 260, 357, 366, 260, 357, 74, 2...  \n",
       "1     [343, 366, 366, 260, 260, 357, 357, 445, 201, ...  \n",
       "2     [445, 197, 196, 380, 341, 395, 170, 99, 332, 4...  \n",
       "3     [208, 260, 28, 199, 357, 204, 5, 141, 164, 212...  \n",
       "4     [208, 28, 260, 199, 70, 357, 204, 12, 72, 164,...  \n",
       "...                                                 ...  \n",
       "4285  [21, 158, 431, 322, 376, 153, 425, 426, 404, 9...  \n",
       "4286   [271, 158, 404, 153, 21, 93, 296, 426, 425, 338]  \n",
       "4287   [271, 153, 425, 426, 21, 93, 296, 338, 158, 404]  \n",
       "4288  [442, 321, 104, 20, 319, 34, 60, 5, 212, 164, ...  \n",
       "4289  [93, 404, 431, 21, 158, 296, 426, 322, 376, 15...  \n",
       "\n",
       "[4290 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### NEW\n",
    "#Derive set of unique trace variants + count\n",
    "logVarClusters[\"act_str\"] = logVarClusters[\"activity\"].apply(lambda x: str(x))\n",
    "#logVar['Count'] = logVar.groupby(['act_str'])['concept:name'].transform('count')\n",
    "logVarClusters = logVarClusters.drop_duplicates(subset=['act_str'], keep='first')\n",
    "logVarClusters = logVarClusters.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54d29952",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 70\n",
    "\n",
    "logVar1 = logVarClusters.loc[logVarClusters['label'] == 0]\n",
    "logVar1 = logVar1.sample(n)\n",
    "\n",
    "logVar2 = logVarClusters.loc[logVarClusters['label'] == 1]\n",
    "logVar2 = logVar2.sample(n)\n",
    "\n",
    "logVar3 = logVarClusters.loc[logVarClusters['label'] == 2]\n",
    "logVar3 = logVar3.sample(n)\n",
    "\n",
    "logVar4 = logVarClusters.loc[logVarClusters['label'] == 3]\n",
    "logVar4 = logVar4.sample(n)\n",
    "\n",
    "logVar5 = logVarClusters.loc[logVarClusters['label'] == 4]\n",
    "logVar5 = logVar5.sample(n)\n",
    "\n",
    "\n",
    "logVar = pd.concat([logVar1, logVar2, logVar3, logVar4, logVar5]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d52ffdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logVar.to_csv('logVar_Sample1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a03492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>activity</th>\n",
       "      <th>case:sublog</th>\n",
       "      <th>caseID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163</td>\n",
       "      <td>20309364</td>\n",
       "      <td>[222, 445, 197, 395, 170, 196, 341, 380, 99, 3...</td>\n",
       "      <td>/usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111</td>\n",
       "      <td>20098000</td>\n",
       "      <td>[343, 196, 341, 197, 445, 380, 222, 170, 395, ...</td>\n",
       "      <td>/usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>4648742</td>\n",
       "      <td>[445, 343, 236, 201, 99, 366, 208, 260, 28, 19...</td>\n",
       "      <td>/usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185</td>\n",
       "      <td>20466285</td>\n",
       "      <td>[343, 222, 395, 197, 170, 445, 380, 99, 196, 1...</td>\n",
       "      <td>/usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891</td>\n",
       "      <td>3631277</td>\n",
       "      <td>[445, 89, 99, 366, 208, 28, 349, 204, 357, 260...</td>\n",
       "      <td>/usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes</td>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>2191</td>\n",
       "      <td>4885164</td>\n",
       "      <td>[236, 99, 366, 208, 260, 28, 204, 12, 394, 5, ...</td>\n",
       "      <td>/usr/share/eventlogs/12718076/CoSeLoG WABO 4.xes</td>\n",
       "      <td>2191</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>3331</td>\n",
       "      <td>6376407</td>\n",
       "      <td>[170, 236, 74, 116, 332, 167, 413, 255, 260, 2...</td>\n",
       "      <td>/usr/share/eventlogs/12718076/CoSeLoG WABO 4.xes</td>\n",
       "      <td>3331</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>3031</td>\n",
       "      <td>5894090</td>\n",
       "      <td>[99, 366, 208, 260, 28, 199, 357, 204, 12, 394...</td>\n",
       "      <td>/usr/share/eventlogs/12718076/CoSeLoG WABO 4.xes</td>\n",
       "      <td>3031</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2744</td>\n",
       "      <td>5454228</td>\n",
       "      <td>[445, 99, 236, 366, 208, 260, 28, 199, 204, 35...</td>\n",
       "      <td>/usr/share/eventlogs/12718076/CoSeLoG WABO 4.xes</td>\n",
       "      <td>2744</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>2623</td>\n",
       "      <td>5307440</td>\n",
       "      <td>[445, 343, 99, 236, 208, 28, 199, 204, 394, 12...</td>\n",
       "      <td>/usr/share/eventlogs/12718076/CoSeLoG WABO 4.xes</td>\n",
       "      <td>2623</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  case:concept:name  \\\n",
       "0      163           20309364   \n",
       "1      111           20098000   \n",
       "2     2021            4648742   \n",
       "3      185           20466285   \n",
       "4      891            3631277   \n",
       "..     ...                ...   \n",
       "345   2191            4885164   \n",
       "346   3331            6376407   \n",
       "347   3031            5894090   \n",
       "348   2744            5454228   \n",
       "349   2623            5307440   \n",
       "\n",
       "                                              activity  \\\n",
       "0    [222, 445, 197, 395, 170, 196, 341, 380, 99, 3...   \n",
       "1    [343, 196, 341, 197, 445, 380, 222, 170, 395, ...   \n",
       "2    [445, 343, 236, 201, 99, 366, 208, 260, 28, 19...   \n",
       "3    [343, 222, 395, 197, 170, 445, 380, 99, 196, 1...   \n",
       "4    [445, 89, 99, 366, 208, 28, 349, 204, 357, 260...   \n",
       "..                                                 ...   \n",
       "345  [236, 99, 366, 208, 260, 28, 204, 12, 394, 5, ...   \n",
       "346  [170, 236, 74, 116, 332, 167, 413, 255, 260, 2...   \n",
       "347  [99, 366, 208, 260, 28, 199, 357, 204, 12, 394...   \n",
       "348  [445, 99, 236, 366, 208, 260, 28, 199, 204, 35...   \n",
       "349  [445, 343, 99, 236, 208, 28, 199, 204, 394, 12...   \n",
       "\n",
       "                                          case:sublog  caseID  label  \n",
       "0    /usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes     163      0  \n",
       "1    /usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes     111      0  \n",
       "2    /usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes    2021      0  \n",
       "3    /usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes     185      0  \n",
       "4    /usr/share/eventlogs/12688511/CoSeLoG WABO 2.xes     891      0  \n",
       "..                                                ...     ...    ...  \n",
       "345  /usr/share/eventlogs/12718076/CoSeLoG WABO 4.xes    2191      4  \n",
       "346  /usr/share/eventlogs/12718076/CoSeLoG WABO 4.xes    3331      4  \n",
       "347  /usr/share/eventlogs/12718076/CoSeLoG WABO 4.xes    3031      4  \n",
       "348  /usr/share/eventlogs/12718076/CoSeLoG WABO 4.xes    2744      4  \n",
       "349  /usr/share/eventlogs/12718076/CoSeLoG WABO 4.xes    2623      4  \n",
       "\n",
       "[350 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVar = pd.read_csv('logVar_Evaluation_Wabo.csv')\n",
    "logVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6e7c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    70\n",
       "1    70\n",
       "2    70\n",
       "3    70\n",
       "4    70\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVar['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b63ede5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "#Calculate Levenshtein Distances\n",
    "logVar[\"activity\"] = logVar[\"activity\"].apply(lambda x: ast.literal_eval(x))\n",
    "logVar[\"c:n_chr\"] = logVar[\"activity\"].apply(lambda x: [chr(int(i)) for i in x])\n",
    "logVar[\"strings\"] = logVar[\"c:n_chr\"].apply(lambda x: ''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f90ab98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logVar[\"length\"] = logVar[\"activity\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a8d9da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVar['length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe5b0c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVar['length'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07bf24c",
   "metadata": {},
   "source": [
    "## Ground truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28bc49d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create dictionary with true labels\n",
    "\n",
    "labelDict1 = logVar['label'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logVar[\"c:n_chr\"] = logVar[\"activity\"].apply(lambda x: [chr(i) for i in x])\n",
    "logVar[\"strings\"] = logVar[\"c:n_chr\"].apply(lambda x: ''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c86d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_calc(features, distance):\n",
    "    n = len(features)\n",
    "    dist_matrix = np.zeros((n,n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            dist_matrix[i,j] = distance(features[i], features[j])\n",
    "            dist_matrix[j,i] = dist_matrix[i,j]\n",
    "    \n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dedc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(DistMatrix):\n",
    "    print('NN:   ' + str(NearestNeighbor(DistMatrix, labelDict1)))\n",
    "    print('P@10: ' + str(PrecisionAtK(DistMatrix, labelDict1, 10)))\n",
    "\n",
    "    triplet = BatchAllTtripletLoss()\n",
    "    print('Tri:  ' + str(triplet.forward(DistMatrix,labelDict1)))\n",
    "    print('Sil:  ' + str(Silhouette(DistMatrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0863e5",
   "metadata": {},
   "source": [
    "## Evaluation based on Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8407d2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx = np.array([[ 0, 12,  8, 10, 12],\\n       [5,  0,  9, 14, 17],\\n       [ 8,  9,  0, 12, 10],\\n       [ 8,  9,  1, 0, 10],\\n       [ 8,  9,  5, 4, 0]])\\n\\nlabelDict2 = {0:1,1:2,2:1,3:3,4:3}\\nNearestNeighbor(x, labelDict2)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def NearestNeighbor(matrix, labelDict):\n",
    "    \n",
    "    clusterLabel = set(labelDict.values())\n",
    "    clusterMeasuredCount = dict.fromkeys(list(clusterLabel), 0)\n",
    "    \n",
    "    for i in range(len(matrix)):\n",
    "        #delete 0 in array matrix[i] for distance between (i,i)\n",
    "        x = np.delete(matrix[i], i) \n",
    "        #identify min distance/value in array\n",
    "        y = min(x)\n",
    "        \n",
    "        #identify position of y AND select first position/pair appearing in the array in case there are muliple pairs with identical min distance\n",
    "        nearestNeighbor = np.where(x == y)[0] #problem if multiple positions??\n",
    "        nearestNeighbor = int(nearestNeighbor[0])\n",
    "        \n",
    "        #true Label for i\n",
    "        trueLabel = labelDict[i]\n",
    "        \n",
    "        #for label comparison add +1 to dict position if position occurs after i (because of the deletion of 0 at the beginning)\n",
    "        if nearestNeighbor >= i:\n",
    "            if trueLabel == labelDict[nearestNeighbor + 1]:\n",
    "                clusterMeasuredCount[trueLabel] += 1         \n",
    "        else:\n",
    "            if trueLabel == labelDict[nearestNeighbor]:\n",
    "                clusterMeasuredCount[trueLabel] += 1\n",
    "    \n",
    "    #Count the (true) number of traces per label/attribute\n",
    "    clusterTrueCount = {}\n",
    "    for i in clusterLabel:\n",
    "        clusterTrueCount[i] = list(labelDict.values()).count(i)\n",
    "    \n",
    "    #Divide number of nearest neighbours with identical label by the respective (true number) of traces with this label\n",
    "    metric = 0\n",
    "    for i in clusterLabel:\n",
    "        metric += clusterMeasuredCount[i] / clusterTrueCount[i]\n",
    "        \n",
    "    #print(clusterMeasuredCount, clusterTrueCount, metric)\n",
    "    \n",
    "    #print(clusterMeasuredCount)\n",
    "    #print(clusterTrueCount)\n",
    "    #print(clusterLabel)\n",
    "    #print(metric)\n",
    "    return metric / len(clusterLabel)\n",
    "\n",
    "\n",
    "'''\n",
    "x = np.array([[ 0, 12,  8, 10, 12],\n",
    "       [5,  0,  9, 14, 17],\n",
    "       [ 8,  9,  0, 12, 10],\n",
    "       [ 8,  9,  1, 0, 10],\n",
    "       [ 8,  9,  5, 4, 0]])\n",
    "\n",
    "labelDict2 = {0:1,1:2,2:1,3:3,4:3}\n",
    "NearestNeighbor(x, labelDict2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0aae66",
   "metadata": {},
   "source": [
    "## Evaluation based on Precision@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a0d082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx3 = np.array([[ 0, 12,  8, 10, 12],\\n       [5,  0,  9, 14, 17],\\n       [ 8,  9,  0, 12, 10],\\n       [ 8,  9,  1, 0, 10],\\n       [ 4,  8,  4, 4, 0]]) # --> Issue: How to select NN when identical distance values !!!\\n\\nlabelDict3 = {0:1,1:2,2:1,3:3,4:3}\\nPrecisionAtK(x3, labelDict3, 2)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_key_by_value(dictionary, value):\n",
    "    for key, val in dictionary.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "    #return None  # Return None if the value is not found in the dictionary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def PrecisionAtK(matrix, labelDict, k):\n",
    "    \n",
    "    clusterLabel = set(labelDict.values())\n",
    "    clusterMeasuredCount = dict.fromkeys(list(clusterLabel), 0)\n",
    "    \n",
    "    \n",
    "    for i in range(len(matrix)):\n",
    "        \n",
    "        #true Label for i\n",
    "        trueLabel = labelDict[i]\n",
    "\n",
    "        \n",
    "        #delete 0 in array matrix[i] for distance between (i,i)   \n",
    "        x = np.delete(matrix[i], i)\n",
    "        \n",
    "        #get all k minimum values\n",
    "        nnValues = []\n",
    "        for l in range(k):\n",
    "            y = min(x)\n",
    "            nnValues.append(y)\n",
    "            x = np.delete(x, np.where(x == y)[0][0])\n",
    "        \n",
    "        \n",
    "        #get location of minimum values\n",
    "        z = np.delete(matrix[i], i)\n",
    "        \n",
    "        #create dict from array with {position:value}\n",
    "        my_dict = {}\n",
    "        for m in range(len(z)):\n",
    "            my_dict[m] = z[m]\n",
    "        \n",
    "        key_list = []\n",
    "        for n in nnValues:\n",
    "            key = get_key_by_value(my_dict, n)\n",
    "            key_list.append(key)\n",
    "            del my_dict[key]\n",
    "        \n",
    "        for o in range(k):\n",
    "            position = list(key_list)[o]\n",
    "\n",
    "            if position >= i:\n",
    "                if trueLabel == labelDict[position + 1]:\n",
    "                    clusterMeasuredCount[trueLabel] += 1\n",
    "\n",
    "            else:\n",
    "                if trueLabel == labelDict[position]:\n",
    "                    clusterMeasuredCount[trueLabel] += 1\n",
    "\n",
    "            #transform array to dict\n",
    "            #get key value from dict\n",
    "            #compare label\n",
    "            #remove key+value from dict\n",
    "\n",
    "            #Need exception in case y == 0 ??\n",
    "            \n",
    "    \n",
    "    #Count the (true) number of traces per label/attribute\n",
    "    clusterTrueCount = {}\n",
    "    for i in clusterLabel:\n",
    "        clusterTrueCount[i] = list(labelDict.values()).count(i)\n",
    "    \n",
    "    #Divide number of nearest neighbours with identical label by the respective (true number) of traces with this label\n",
    "    metric = 0\n",
    "    for i in clusterLabel:\n",
    "        metric += clusterMeasuredCount[i] / k / clusterTrueCount[i]\n",
    "        \n",
    "    #print(clusterMeasuredCount, clusterTrueCount, metric)\n",
    "    \n",
    "    #print(clusterLabel)\n",
    "    #print(metric)\n",
    "    return metric / len(clusterLabel)\n",
    "\n",
    "\n",
    "'''\n",
    "x3 = np.array([[ 0, 12,  8, 10, 12],\n",
    "       [5,  0,  9, 14, 17],\n",
    "       [ 8,  9,  0, 12, 10],\n",
    "       [ 8,  9,  1, 0, 10],\n",
    "       [ 4,  8,  4, 4, 0]]) # --> Issue: How to select NN when identical distance values !!!\n",
    "\n",
    "labelDict3 = {0:1,1:2,2:1,3:3,4:3}\n",
    "PrecisionAtK(x3, labelDict3, 2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18183bf",
   "metadata": {},
   "source": [
    "## Triplet\n",
    "\n",
    "see: https://towardsdatascience.com/triplet-loss-advanced-intro-49a07b7d8905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b8138ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "836bd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_mask(labels):\n",
    "    \n",
    "    # step 1 - get a mask for distinct indices\n",
    "    ###print('labels', labels)\n",
    "    # shape: (batch_size, batch_size)\n",
    "    indices_equal = torch.eye(labels.size()[0], dtype=torch.bool, device=labels.device)\n",
    "    ###print('equal', indices_equal)\n",
    "    indices_not_equal = torch.logical_not(indices_equal)\n",
    "    ###print('not_equal', indices_not_equal)\n",
    "\n",
    "    # shape: (batch_size, batch_size, 1)\n",
    "    i_not_equal_j = indices_not_equal.unsqueeze(2)\n",
    "    ###print('i_not_j - unsqueeze2', i_not_equal_j)\n",
    "    # shape: (batch_size, 1, batch_size)\n",
    "    i_not_equal_k = indices_not_equal.unsqueeze(1)\n",
    "    ###print('i_not_k - unsqueeze1', i_not_equal_k)\n",
    "    # shape: (1, batch_size, batch_size)\n",
    "    j_not_equal_k = indices_not_equal.unsqueeze(0)\n",
    "    ###print('j_not_k - unsqueeze0', i_not_equal_k)\n",
    "    # Shape: (batch_size, batch_size, batch_size)\n",
    "    distinct_indices = torch.logical_and(torch.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "    ###print('distinct!!!!', distinct_indices)\n",
    "\n",
    "    # step 2 - get a mask for valid anchor-positive-negative triplets\n",
    "    # shape: (batch_size, batch_size)\n",
    "    labels_equal = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
    "    ###print('labels_equal', labels_equal)\n",
    "    # shape: (batch_size, batch_size, 1)\n",
    "    i_equal_j = labels_equal.unsqueeze(2)\n",
    "    ###print('i_equal_j', i_equal_j)\n",
    "    # shape: (batch_size, 1, batch_size)\n",
    "    i_equal_k = labels_equal.unsqueeze(1)\n",
    "    ###print('i_equal_k', i_equal_k)\n",
    "    # shape: (batch_size, batch_size, batch_size)\n",
    "    valid_indices = torch.logical_and(i_equal_j, torch.logical_not(i_equal_k))\n",
    "    ###print('valid_indices!!!', valid_indices)\n",
    "    \n",
    "\n",
    "    # step 3 - combine two masks\n",
    "    mask = torch.logical_and(distinct_indices, valid_indices)\n",
    "    ###print('mask!!', mask)\n",
    "    return mask\n",
    "\n",
    "    \"\"\"compute a mask for valid triplets\n",
    "    Args:\n",
    "        labels: Batch of integer labels. shape: (batch_size,)\n",
    "    Returns:\n",
    "        Mask tensor to indicate which triplets are actually valid. Shape: (batch_size, batch_size, batch_size)\n",
    "        A triplet is valid if:\n",
    "        `labels[i] == labels[j] and labels[i] != labels[k]`\n",
    "        and `i`, `j`, `k` are different.\n",
    "    \"\"\"\n",
    "    \n",
    "class custom_activation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(custom_activation, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x[x>0] = 1\n",
    "        x[x<=0] = 0\n",
    "        return x\n",
    "\n",
    "\n",
    "class BatchAllTtripletLoss(nn.Module):\n",
    "  \"\"\"Uses all valid triplets to compute Triplet loss\n",
    "\n",
    "  Args:\n",
    "    margin: Margin value in the Triplet Loss equation\n",
    "  \"\"\"\n",
    "  def __init__(self, margin=0): #default margin = 0\n",
    "    super().__init__()\n",
    "    self.margin = margin\n",
    "    self.relu = nn.ReLU() #new\n",
    "    self.custom = custom_activation()\n",
    "    \n",
    "  def forward(self, distance_matrix, labels):\n",
    "    \"\"\"computes loss value.\n",
    "\n",
    "    Args:\n",
    "      embeddings: Batch of embeddings, e.g., output of the encoder. shape: (batch_size, embedding_dim)\n",
    "      labels: Batch of integer labels associated with embeddings. shape: (batch_size,)\n",
    "\n",
    "    Returns:\n",
    "      Scalar loss value.\n",
    "    \"\"\"\n",
    "    # step 1 - convert to tensor format\n",
    "    distance_matrix = torch.tensor(distance_matrix)\n",
    "    labels = torch.tensor(list(labels.values()))\n",
    "\n",
    "\n",
    "    # step 2 - compute loss values for all triplets by applying broadcasting to distance matrix\n",
    "\n",
    "    # shape: (batch_size, batch_size, 1)\n",
    "    anchor_positive_dists = distance_matrix.unsqueeze(2)\n",
    "    # shape: (batch_size, 1, batch_size)\n",
    "    anchor_negative_dists = distance_matrix.unsqueeze(1)\n",
    "    # get loss values for all possible n^3 triplets\n",
    "    # shape: (batch_size, batch_size, batch_size)\n",
    "    triplet_loss = anchor_negative_dists - anchor_positive_dists + self.margin\n",
    "    ###print('tl0',triplet_loss)\n",
    "\n",
    "    # step 3 - filter out invalid or easy triplets by setting their loss values to 0\n",
    "\n",
    "    # shape: (batch_size, batch_size, batch_size)\n",
    "    mask = get_triplet_mask(labels)\n",
    "    ###print('mask', mask)\n",
    "    triplet_loss *= mask\n",
    "    ###print(triplet_loss)\n",
    "    ###print('tl1:', triplet_loss)\n",
    "    # easy triplets have negative loss values\n",
    "    \n",
    "    triplet_loss = self.custom(triplet_loss)\n",
    "    ###print(triplet_loss)\n",
    "    #triplet_loss = F.relu(triplet_loss)\n",
    "\n",
    "    # step 4 - compute scalar loss value by averaging positive losses\n",
    "    \n",
    "    triLossNonZero = (triplet_loss != 0).nonzero(as_tuple=True)\n",
    "    labelTorchUnique = torch.unique(labels, return_counts=True)\n",
    "    \n",
    "    nonZero = len(triLossNonZero[0])\n",
    "    triLossSum = []\n",
    "    for i in range(nonZero):\n",
    "        #Identify L_a --> In Class\n",
    "        t1 = triLossNonZero[0][i]\n",
    "        labelIn = labels[t1]\n",
    "        positionIn = int((labelTorchUnique[0] == labelIn).nonzero(as_tuple=False))\n",
    "        countIn = labelTorchUnique[1][positionIn]\n",
    "\n",
    "        #Identify L_b --> Out Class\n",
    "        t3 = triLossNonZero[2][i]\n",
    "        labelOut = labels[t3]\n",
    "        positionOut = int((labelTorchUnique[0] == labelOut).nonzero(as_tuple=False))\n",
    "        countOut = labelTorchUnique[1][positionOut]\n",
    "\n",
    "        #Calculate loss\n",
    "        value = (1/countIn)*(1/countIn)*(1/countOut)  \n",
    "        ###print(countIn)\n",
    "        ###print(countOut)\n",
    "        triLossSum.append(value)\n",
    "    \n",
    "    #finally divide by |A|^2-|A|\n",
    "    A = len(labelTorchUnique[0])  \n",
    "    lossValue = sum(triLossSum) / (A*A-A)\n",
    "        \n",
    "    #OLD\n",
    "    #E_triplet = (1 / (A^2 - A)) *\n",
    "    #num_positive_losses = (triplet_loss > eps).float().sum()\n",
    "    #print(num_positive_losses)\n",
    "    #print(triplet_loss.sum())\n",
    "    #triplet_loss = triplet_loss.sum() / (num_positive_losses + eps)\n",
    "    \n",
    "\n",
    "    return lossValue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f12a92e",
   "metadata": {},
   "source": [
    "## Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26715870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def Silhouette(distMatrix, labelDict):\n",
    "    labelDictList = list(labelDict.values())\n",
    "    return metrics.silhouette_score(distMatrix, labelDictList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9012b060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [222, 445, 197, 395, 170, 196, 341, 380, 99, 3...\n",
       "1      [343, 196, 341, 197, 445, 380, 222, 170, 395, ...\n",
       "2      [445, 343, 236, 201, 99, 366, 208, 260, 28, 19...\n",
       "3      [343, 222, 395, 197, 170, 445, 380, 99, 196, 1...\n",
       "4      [445, 89, 99, 366, 208, 28, 349, 204, 357, 260...\n",
       "                             ...                        \n",
       "345    [236, 99, 366, 208, 260, 28, 204, 12, 394, 5, ...\n",
       "346    [170, 236, 74, 116, 332, 167, 413, 255, 260, 2...\n",
       "347    [99, 366, 208, 260, 28, 199, 357, 204, 12, 394...\n",
       "348    [445, 99, 236, 366, 208, 260, 28, 199, 204, 35...\n",
       "349    [445, 343, 99, 236, 208, 28, 199, 204, 394, 12...\n",
       "Name: activity, Length: 350, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVar['activity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f908a1",
   "metadata": {},
   "source": [
    "### Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2153307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ast\n",
    "#\n",
    "##Calculate Levenshtein Distances\n",
    "#logVar[\"activity\"] = logVar[\"activity\"].apply(lambda x: ast.literal_eval(x))\n",
    "#logVar[\"c:n_chr\"] = logVar[\"activity\"].apply(lambda x: [chr(int(i)) for i in x])\n",
    "#logVar[\"strings\"] = logVar[\"c:n_chr\"].apply(lambda x: ''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "babbef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Levenshtein Distance\n",
    "\n",
    "List = list(logVar[\"strings\"])\n",
    "\n",
    "dist_matrix = np.zeros((len(List),len(List)),dtype=int)\n",
    "\n",
    "for i in range(0,len(List)):\n",
    "    for j in range(0,len(List)):\n",
    "        dist_matrix[i,j] = distance(List[i],List[j])\n",
    "\n",
    "lev_dis = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5d8a65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.6028571428571429\n",
      "P@10: 0.398\n",
      "Sil:  -0.0791734036326659\n",
      "Tri:  tensor(0.5038)\n"
     ]
    }
   ],
   "source": [
    "Matrix = lev_dis\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d769e7",
   "metadata": {},
   "source": [
    "### Normalized Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecb15751",
   "metadata": {},
   "outputs": [],
   "source": [
    "List = logVar[\"strings\"]\n",
    "\n",
    "n = len(List)\n",
    "dist_matrix = np.zeros((n,n))    # initialize distance matrix to a square of zeros\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = distance(List[i], List[j]) / max(len(List[i]),len(List[j]))\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]       # for the symmetric part, no computation\n",
    "\n",
    "lev_dis_norm = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e767dec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.5999999999999999\n",
      "P@10: 0.40028571428571436\n",
      "Sil:  -0.032571737993892784\n",
      "Tri:  tensor(0.5151)\n"
     ]
    }
   ],
   "source": [
    "Matrix = lev_dis_norm\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7dd7ae",
   "metadata": {},
   "source": [
    "### Cosine based on 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbe30ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 1-gram\n",
    "\n",
    "def createVector(charList):\n",
    "    #dtype = [('structure', 'S10'), ('relfrequ', float)]\n",
    "    arrayList = np.array(charList)\n",
    "    unique, counts = np.unique(arrayList, return_counts=True)\n",
    "    #calculate relative frequency\n",
    "    relFrequList = np.array((unique, counts)).T\n",
    "    uniqueList = list(unique)\n",
    "    return relFrequList[relFrequList[:, 0].argsort()]\n",
    "    #check completeness\n",
    "    #if 'tree' not in uniqueList:\n",
    "        #relFrequList = np.append(relFrequList, np.array([['tree', 0]]), axis=0)\n",
    "        #print(relFrequList)\n",
    "\n",
    "        \n",
    "#Change data format from string to list of unique characters\n",
    "logVar[\"1-gram\"] = logVar[\"c:n_chr\"].apply(lambda x: createVector(tuple(x)))\n",
    "#logVar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2556cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignArrays(array1, array2):\n",
    "    commonSet = set(array1[:,0]).union(array2[:,0])\n",
    "    \n",
    "    for i in commonSet:\n",
    "        if i not in array1[:,0]:\n",
    "            array1 = np.append(array1, np.array([[i, '0']]), axis=0)\n",
    "        if i not in array2[:,0]:\n",
    "            array2 = np.append(array2, np.array([[i, '0']]), axis=0)\n",
    "    return array1[array1[:, 0].argsort()], array2[array2[:, 0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51bc8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot embedding\n",
    "'''\n",
    "def alignArrays_OneHotEmbedding(array1, array2):\n",
    "    \n",
    "    for i in range(len(array1)):\n",
    "        if int(array1[:,1][i]) > 1:\n",
    "            array1[:,1][i] = 1\n",
    "    \n",
    "    for i in range(len(array2)):\n",
    "        if int(array2[:,1][i]) > 1:\n",
    "            array2[:,1][i] = 1\n",
    "               \n",
    "    commonSet = set(array1[:,0]).union(array2[:,0])\n",
    "    #print(commonSet)\n",
    "        \n",
    "    for i in commonSet:\n",
    "        if i not in array1[:,0]:\n",
    "            array1 = np.append(array1, np.array([[i, '0']]), axis=0)\n",
    "        if i not in array2[:,0]:\n",
    "            array2 = np.append(array2, np.array([[i, '0']]), axis=0)\n",
    "    return array1[array1[:, 0].argsort()], array2[array2[:, 0].argsort()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2a7a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def cosineDist(frequVector1, frequVector2):\n",
    "    Vector1, Vector2 = alignArrays(frequVector1, frequVector2)\n",
    "    a = Vector1[:,1].astype(int)\n",
    "    b = Vector2[:,1].astype(int)\n",
    "    dist_matrix = distance.cosine(a, b)\n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c57ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on 1-gram\n",
    "\n",
    "cos1_dis = matrix_calc(logVar[\"1-gram\"],cosineDist)\n",
    "results(cos1_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63a2bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on 1-gram\n",
    "'''\n",
    "listVec = logVar[\"1-gram\"]\n",
    "\n",
    "n = len(listVec)\n",
    "dist_matrix = np.zeros((n,n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = cosineDist(listVec[i], listVec[j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]  \n",
    "        \n",
    "cos1_dis = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bef9d6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.6485714285714285\n",
      "P@10: 0.44114285714285717\n",
      "Tri:  tensor(0.5244)\n",
      "Sil:  -0.040659820960443654\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Matrix = cos1_dis\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13361d6f",
   "metadata": {},
   "source": [
    "### Cosine based on 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58972a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change data format from string to list of unique characters\n",
    "#logVar[\"charList\"] = logVar[\"trace_variant\"].apply(lambda x: list(x))\n",
    "#logVar\n",
    "\n",
    "def df_list(list_of_char):\n",
    "    extList = list_of_char.copy()\n",
    "    extList.insert(0, '*') \n",
    "    extList.append('$')\n",
    "    list_new = []\n",
    "    for i in range(len(extList)):\n",
    "        new = ''.join(extList[i:i+2])\n",
    "        list_new.append(new)\n",
    "    del list_new[-1]\n",
    "    return list_new\n",
    "\n",
    "#Change data format from string to list of unique characters\n",
    "logVar[\"dfList\"] = logVar[\"c:n_chr\"].apply(lambda x: df_list(x))\n",
    "#logVar\n",
    "\n",
    "logVar[\"2-gram\"] = logVar[\"dfList\"].apply(lambda x: createVector(x))\n",
    "#logVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba5f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on 2-gram\n",
    "\n",
    "cos2_dis = matrix_calc(logVar[\"2-gram\"],cosineDist)\n",
    "results(cos2_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db1c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 3-gram\n",
    "\n",
    "#Change data format from string to list of unique characters\n",
    "logVar[\"charList\"] = logVar[\"c:n_chr\"].apply(lambda x: list(x))\n",
    "\n",
    "def df_list2(list_of_char):\n",
    "    extList = list_of_char.copy()\n",
    "    extList.insert(0, '*') \n",
    "    extList.append('$')\n",
    "    list_new = []\n",
    "    for i in range(len(extList) - 1):\n",
    "        new = ''.join(extList[i:i+3])\n",
    "        list_new.append(new)\n",
    "    del list_new[-1]\n",
    "    return list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe62ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logVar[\"dfList2\"] = logVar[\"charList\"].apply(lambda x: df_list2(x))\n",
    "logVar[\"3-gram\"] = logVar[\"dfList2\"].apply(lambda x: createVector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on 3-gram\n",
    "\n",
    "cos3_dis = matrix_calc(logVar[\"3-gram\"],cosineDist)\n",
    "results(cos3_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08af481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on 2-gram\n",
    "'''\n",
    "listVec = logVar[\"2-gram\"]\n",
    "\n",
    "n = len(listVec)\n",
    "dist_matrix = np.zeros((n,n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = cosineDist(listVec[i], listVec[j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]  \n",
    "        \n",
    "cos2_dis = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2adf27e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.6114285714285714\n",
      "P@10: 0.39285714285714285\n",
      "Tri:  tensor(0.5258)\n",
      "Sil:  -0.03482066301470471\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Matrix = cos2_dis\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9207a277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.6514285714285715\n",
      "P@10: 0.426\n",
      "Tri:  tensor(0.5296)\n",
      "Sil:  -0.036425353273712775\n"
     ]
    }
   ],
   "source": [
    "#Aggregation\n",
    "\n",
    "aggregate = cos1_dis + cos2_dis\n",
    "\n",
    "Matrix = aggregate\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b369cdfd",
   "metadata": {},
   "source": [
    "## Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832340f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance\n",
    "# see https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy\n",
    "\n",
    "def euclidDist(frequVector1, frequVector2):\n",
    "    Vector1, Vector2 = alignArrays(frequVector1, frequVector2)\n",
    "    a = Vector1[:,1].astype(float)\n",
    "    b = Vector2[:,1].astype(float)\n",
    "    euclidean_dist = np.linalg.norm(a-b)\n",
    "    return euclidean_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean distance based on 1-gram\n",
    "\n",
    "euc1_dis = matrix_calc(logVar[\"1-gram\"],euclidDist)\n",
    "results(euc1_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d450ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean distance based on 2-gram\n",
    "\n",
    "euc2_dis = matrix_calc(logVar[\"2-gram\"],euclidDist)\n",
    "results(euc2_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc89c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean distance based on 3-gram\n",
    "\n",
    "euc3_dis = matrix_calc(logVar[\"3-gram\"],euclidDist)\n",
    "results(euc3_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregation\n",
    "\n",
    "agg_euc = euc1_dis + euc2_dis\n",
    "results(agg_euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e371cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efaef19c",
   "metadata": {},
   "source": [
    "### Jaccard based on 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "feb39b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance based on activity type\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    s1, s2 = set(list1), set(list2)\n",
    "    return 1 - len(s1 & s2) / len(s1 | s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c951f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jaccard based on 1-gram\n",
    "Jacc1_dis = matrix_calc(logVar[\"charList\"],jaccard_similarity)\n",
    "results(Jacc1_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jaccard based on 2-gram\n",
    "Jacc2_dis = matrix_calc(logVar[\"dfList\"],jaccard_similarity)\n",
    "results(Jacc2_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f2954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jaccard based on 3-gram\n",
    "Jacc3_dis = matrix_calc(logVar[\"dfList2\"],jaccard_similarity)\n",
    "results(Jacc3_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d810665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregation\n",
    "\n",
    "agg_jacc1 = Jacc1_dis + Jacc2_dis\n",
    "results(agg_jacc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec677f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_jacc2 = Jacc1_dis + Jacc2_dis + Jacc3_dis\n",
    "results(agg_jacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122eab73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17049e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ListChar = list(logVar[\"activity\"])\n",
    "\n",
    "n = len(ListChar)\n",
    "dist_matrix = np.zeros((n,n))    # initialize distance matrix to a square of zeros\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = jaccard_similarity(ListChar[i], ListChar[j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]       # for the symmetric part, no computation\n",
    "        \n",
    "jacc1_dis = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8606da9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.6457142857142857\n",
      "P@10: 0.43742857142857144\n",
      "Tri:  tensor(0.5236)\n",
      "Sil:  -0.03552169942010938\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Matrix = jacc1_dis\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "664a9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance based on adjacency relations\n",
    "\n",
    "#Create list of directly follow relations\n",
    "'''\n",
    "def df_list(list_of_char):\n",
    "    extList = list_of_char.copy()\n",
    "    extList.insert(0, '*') \n",
    "    extList.append('$')\n",
    "    list_new = []\n",
    "    for i in range(len(extList)):\n",
    "        new = ''.join(extList[i:i+2])\n",
    "        list_new.append(new)\n",
    "    del list_new[-1]\n",
    "    return list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c8c2746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change data format from string to list of unique characters\n",
    "#logVar[\"dfList\"] = logVar[\"c:n_chr\"].apply(lambda x: df_list(x))\n",
    "#logVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da1ba214",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ListChar = list(logVar[\"dfList\"])\n",
    "\n",
    "n = len(ListChar)\n",
    "dist_matrix = np.zeros((n,n))    # initialize distance matrix to a square of zeros\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = jaccard_similarity(ListChar[i], ListChar[j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]       # for the symmetric part, no computation\n",
    "        \n",
    "jacc2_dis = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b14857d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.6114285714285714\n",
      "P@10: 0.3868571428571429\n",
      "Tri:  tensor(0.5255)\n",
      "Sil:  -0.026308473382435957\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Matrix = jacc2_dis\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4ceb28f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.6828571428571428\n",
      "P@10: 0.44371428571428567\n",
      "Tri:  tensor(0.5286)\n",
      "Sil:  -0.03293724249347572\n"
     ]
    }
   ],
   "source": [
    "#Aggregation\n",
    "'''\n",
    "aggregate = jacc1_dis + jacc2_dis\n",
    "\n",
    "Matrix = aggregate\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8982bc",
   "metadata": {},
   "source": [
    "## Graph based measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26f94a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. transfer strings (string numbers) to integers --> HERE we need a new encoding!\n",
    "\n",
    "#logVar = logVar.astype({\"trace_variant\": str}) #--> only needed if list values were transformed to int at one point\n",
    "\n",
    "def intEncoder(character_List):\n",
    "    return [np.where(np.array(list(dict.fromkeys(character_List)))==e)[0][0]for e in character_List]\n",
    "\n",
    "logVar[\"intList\"] = logVar[\"activity\"].apply(lambda x: intEncoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26a1b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. transfer intList to int_tupleList\n",
    "\n",
    "#Create tuple lists\n",
    "def tuple_list(list_of_encodedActivities):\n",
    "    #list.insert(0, '*')\n",
    "    #list.append('*')\n",
    "    list_new = []\n",
    "    last_element = list_of_encodedActivities[-1]\n",
    "    for i in range(len(list_of_encodedActivities)):\n",
    "        new = tuple(list_of_encodedActivities[i:i+2])\n",
    "        list_new.append(new)\n",
    "    del list_new[-1]\n",
    "    if list_of_encodedActivities.count(last_element) == 1: #check wether last activity in trace has some adjancency relation\n",
    "        list_new.append((last_element,)) ### NOT Correct\n",
    "    return list_new\n",
    "\n",
    "#q = [0,0,0,0,1,1,2,3,4,5,3,2,4,0,5,6]\n",
    "#tuple_list(q)\n",
    "\n",
    "logVar[\"int_tupleList\"] = logVar[\"intList\"].apply(lambda x: tuple_list(x))\n",
    "#logVar[\"int_tupleList\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4db1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. generate Adjacency List\n",
    "\n",
    "def adj_list(list_of_tuples):\n",
    "    adj_list_new = {}\n",
    "    try:\n",
    "        for node1, node2 in list_of_tuples:\n",
    "            #print(node1, node2)\n",
    "            if node1 not in adj_list_new:\n",
    "                newlist = []\n",
    "                newlist.append(node2)\n",
    "                adj_list_new[node1] = newlist\n",
    "                #print(adj_list3)\n",
    "        \n",
    "            else:\n",
    "                if node2 not in adj_list_new[node1]:\n",
    "                    #mylist.extend(adj_list3[node1])\n",
    "                    adj_list_new[node1].append(node2)\n",
    "                    #print(adj_list3)\n",
    "                    #adj_list3[node1] = mylist\n",
    "    \n",
    "    #in case activity has no adjacent activity - only possible for last activity --> tuple: (lastAct,)\n",
    "    except ValueError as ve:\n",
    "        lastValue = list_of_tuples[-1][0] \n",
    "        adj_list_new[lastValue] = list()\n",
    "    return list(adj_list_new.values())\n",
    "\n",
    "#q = [0,0,0,0,1,1,2,3,4,5,3,2,4,0,5,6]\n",
    "#l = tuple_list(q)\n",
    "#adj_list(l)\n",
    "\n",
    "logVar[\"int_adjList\"] = logVar[\"int_tupleList\"].apply(lambda x: adj_list(x))\n",
    "#logVar[\"int_adjList\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5433d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def bfs_4(graph, start, end):\n",
    "    \n",
    "    graph = {v: k for v, k in enumerate(graph)}\n",
    "    #print(start, end)\n",
    "    queue = deque([(start, 0)])\n",
    "    seen = set()\n",
    "    while queue:\n",
    "        #print(queue)\n",
    "        node, distance = queue.popleft()\n",
    "        #if not node:\n",
    "            #print(start, end, queue)\n",
    "            #print(\"GRAPH LIST\", graph)\n",
    "        if node in seen:\n",
    "            continue\n",
    "        seen.add(node)\n",
    "        if node == end:\n",
    "            return distance \n",
    "        for adjacent in graph.get(node, []):\n",
    "            queue.append((adjacent, distance + 1))\n",
    "        \n",
    "#x = {0: [0, 1], 1: [2, 1, 0, int], 2:[2], [3: [1, 5, 3, 7], 4: [3], 5: [6, 5], 6: [1, 7], 7: [8, 9, 7], 8: [5, 8, 10], 9: [3]}\n",
    "#y = [[0, 1, 5], [1, 2], [3, 4], [4, 2], [5, 0], [3, 6], []]\n",
    "#bfs_4(y, 1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01800b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "def reverse_graph(graph):\n",
    "    reversed_graph = defaultdict(list)\n",
    "    for node in graph:\n",
    "        for neighbor in graph[node]:\n",
    "            reversed_graph[neighbor].append(node)\n",
    "    return reversed_graph\n",
    "\n",
    "\n",
    "def bfs_5(graph, start, end):\n",
    "    queue = deque([(start, 0)])\n",
    "    seen = set()\n",
    "    visited = {}\n",
    "    while queue:\n",
    "        node, distance = queue.popleft()\n",
    "        if node in seen:\n",
    "            continue\n",
    "        seen.add(node)\n",
    "        if node == end: # maybe quicker if adjacent directly checked\n",
    "            return visited\n",
    "        for adjacent in graph.get(node, []):\n",
    "            queue.append((adjacent, distance + 1))\n",
    "            if adjacent not in visited:\n",
    "                visited.update({adjacent:distance})\n",
    "\n",
    "            \n",
    "def common_ancestors(graph, node1, node2): \n",
    "    #remove cross type edge between node1 and node2\n",
    "    graph[node1].remove(node2) #maybe issue, if graph is changed and not copy of graph?\n",
    "    graph = {v: k for v, k in enumerate(graph)}\n",
    "    graphReverse = reverse_graph(graph)\n",
    "    setNode1 = bfs_5(graphReverse, node1, 0)\n",
    "    setNode2 = bfs_5(graphReverse, node2, 0)\n",
    "    if next((a for a in list(setNode1) if a in list(setNode2)), None) == None:\n",
    "        firstCommonAnces = next((a for a in list(setNode2) if a in list(setNode1)), None)\n",
    "    else:\n",
    "        firstCommonAnces = next((a for a in list(setNode1) if a in list(setNode2)), 0)\n",
    "    \n",
    "    #uses a hash map to identify the first common ancestor in both lists\n",
    "    #looks for the first common ancestor in setNode1, which can also be found in setNode2 \n",
    "    #--> this might not be the closest distance between setNode1 and setNode2\n",
    "    #--> e.g., for x= [0,1,3,7,5,6] and y= [4,5,7,8,3] 7 might be closest ancestor, although algo detects 3 !\n",
    "    #distance = setNode1[firstCommonAnces] + setNode2[firstCommonAnces]\n",
    "    \n",
    "    \n",
    "    if firstCommonAnces != None:   # ISSUE: in some cases the firstCommonAnces cannot be detected!\n",
    "        ancesDistNode1 =  setNode1[firstCommonAnces] + 1 #the edge from node1 to first parent is counted as 0 by algorithm, therefore +1\n",
    "        ancesDistNode2 =  setNode2[firstCommonAnces] + 1\n",
    "        numberSkips = abs(ancesDistNode1 - ancesDistNode2)\n",
    "        numberCross = min(ancesDistNode1, ancesDistNode2)\n",
    "    else:\n",
    "        numberSkips, numberCross = (0,1)\n",
    "    return numberSkips, numberCross\n",
    "    #if all(x in crossType for x in i):\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#graphList = [[1], [2, 4, 1], [3, 2, 1], [], [5, 4], [5, 4, 6], [7], []]\n",
    "#c = [[1, 4], [2], [3], [0, 5], [3, 5], []]\n",
    "#c2 = {v: k for v, k in enumerate(c)}\n",
    "#common_ancestors(c, 4, 5)\n",
    "#reverse_graph(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a163feac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create List for decoding traces\n",
    "from collections import OrderedDict\n",
    "logVar[\"indexList\"] = logVar[\"activity\"].apply(lambda x: list(OrderedDict.fromkeys(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e36477c",
   "metadata": {},
   "source": [
    "### Cosine Edge Type + length (no df relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6327e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph1:\n",
    "    # instance variables\n",
    "    def __init__(self, graph_list2, indexList):\n",
    "        # v is the number of nodes/vertices\n",
    "        self.time = 0\n",
    "        self.traversal_array = []\n",
    "        self.structural_array = [['sequ', 1]]\n",
    "        #self.structural_array = []\n",
    "        self.graph_list = graph_list2\n",
    "        self.v = len(graph_list2)\n",
    "        self.indexList = indexList\n",
    "\n",
    "    # function for dfs\n",
    "    def dfs(self):\n",
    "        self.start_time = [-1]*self.v\n",
    "        self.end_time = [-1]*self.v\n",
    " \n",
    "        for node in range(self.v):\n",
    "            if self.start_time[node] == -1:\n",
    "                self.traverse_dfs(node)\n",
    "                \n",
    "        return np.array(self.structural_array)\n",
    "        #print()\n",
    "        #print(\"DFS Traversal: \", self.traversal_array)\n",
    "        #print()\n",
    " \n",
    "    def traverse_dfs(self, node):\n",
    "        self.traversal_array.append(node)\n",
    "        # get the starting time\n",
    "        self.start_time[node] = self.time\n",
    "        self.time += 1\n",
    "        # traverse through the neighbours\n",
    "        for neighbour in self.graph_list[node]:\n",
    "\n",
    "            # when the neighbor was not yet visited\n",
    "            if self.start_time[neighbour] == -1:                \n",
    "                self.structural_array[0][1] += 0\n",
    "                self.traverse_dfs(neighbour)\n",
    "                \n",
    "            # otherwise when the neighbour's visit is still ongoing:\n",
    "            elif self.end_time[neighbour] == -1:\n",
    "                if node == neighbour:\n",
    "                    self.structural_array.append(['1back ',1])\n",
    "                    #self.structural_array.append(['back ',1])\n",
    "                    #self.structural_array.append([str(1)+'b'])\n",
    "                \n",
    "                elif node in self.graph_list[neighbour]:\n",
    "                    self.structural_array.append(['2back ',2])\n",
    "                    #self.structural_array.append(['back ',2])\n",
    "                    #self.structural_array.append(str(2)+'b')\n",
    "                    \n",
    "                else:\n",
    "                    x = bfs_4(self.graph_list, neighbour, node)\n",
    "                    self.structural_array.append([str(x+1)+'back ',x+1])\n",
    "                    #self.structural_array.append(['back ',x+1])\n",
    "                    #self.structural_array.append(str(x+1)+'b')\n",
    "                \n",
    "            # otherwise when the neighbour's visit started before the current node's visit:\n",
    "            elif self.start_time[node] < self.start_time[neighbour]:\n",
    "                graph_list_copy = copy.deepcopy(self.graph_list)\n",
    "                graph_list_copy[node].remove(neighbour)\n",
    "                y = bfs_4(graph_list_copy, node, neighbour)\n",
    "                self.structural_array.append([str(y-1)+'forward ',y-1])\n",
    "                #self.structural_array.append(['forward ' ,y-1])\n",
    "                #self.structural_array.extend((y-1)*['forward']) # -1 to exclude one edge: (A:B,C;B:C;C:[]) ...the dist A --> C is 2 without forward edge, but we are skipping only one activity\n",
    "                #self.structural_array.append(str(y-1)+'f')\n",
    "                \n",
    "            else:\n",
    "                #Possibly first check, whether two nodes connected by cross-type have identical parent\n",
    "                numberSkips, numberCross = common_ancestors(self.graph_list, node, neighbour)\n",
    "                #self.structural_array.append(['forward ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]),numberSkips])\n",
    "                self.structural_array.append([str(numberCross)+'cross ',numberCross])\n",
    "\n",
    "    \n",
    "        # Indentation corrected:\n",
    "        self.end_time[node] = self.time\n",
    "        self.time += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4583d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def transform_list_of_pairs(pairs):\n",
    "    return [pair[0] for pair in pairs]\n",
    "\n",
    "\n",
    "\n",
    "def count_entries(input_list):\n",
    "    # Count the occurrences of each unique entry in the list\n",
    "    counter = Counter(input_list)\n",
    "    \n",
    "    # Create a NumPy array from the counter dictionary\n",
    "    result = np.array([[key, count] for key, count in counter.items()], dtype=object)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "#input_list = ['sequ', '2back', '2back']\n",
    "#result = count_entries(input_list)\n",
    "#print(result)\n",
    "\n",
    "logVar[\"int_strucLengthList2\"] = logVar.apply(lambda x: Graph1(x.int_adjList, x.indexList).dfs(), axis =1)\n",
    "logVar[\"relFrequVec1\"] = logVar[\"int_strucLengthList2\"].apply(lambda x: transform_list_of_pairs(x))\n",
    "logVar[\"relFrequVec1\"] = logVar[\"relFrequVec1\"].apply(lambda x: count_entries(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on edge types\n",
    "cos_graph_dis = matrix_calc(logVar[\"relFrequVec1\"],cosineDist)\n",
    "results(cos_graph_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on edge types\n",
    "agg_cos = cos1_dis + cos2_dis + cos_graph_dis\n",
    "results(agg_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d4f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c66e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "logVar[\"int_strucLengthList2\"] = logVar.apply(lambda x: Graph1(x.int_adjList, x.indexList).dfs(), axis =1)\n",
    "\n",
    "logVar[\"relFrequVec2\"] = logVar[\"int_strucLengthList2\"].apply(lambda x: pd.DataFrame(x, columns=['String', 'Value']))\n",
    "logVar[\"relFrequVec2\"] = logVar[\"relFrequVec2\"].apply(lambda x: x.groupby('String', as_index=False)['Value'].sum())\n",
    "logVar[\"relFrequVec2\"] = logVar[\"relFrequVec2\"].apply(lambda x: x.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb0dab48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\la1949\\Anaconda3\\envs\\pm4py\\lib\\site-packages\\scipy\\spatial\\distance.py:636: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "listVec = list(logVar[\"relFrequVec2\"])\n",
    "\n",
    "n = len(listVec)\n",
    "dist_matrix = np.zeros((n,n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = cosineDist(listVec[i], listVec[j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]  \n",
    "        \n",
    "cos_graph_dis = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3834867d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.2\n",
      "P@10: 0.2\n",
      "Tri:  tensor(0.0250)\n",
      "Sil:  -0.18235015360403387\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Matrix = cos_graph_dis\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "435032ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.64\n",
      "P@10: 0.418\n",
      "Tri:  tensor(0.5281)\n",
      "Sil:  -0.035564958668923494\n"
     ]
    }
   ],
   "source": [
    "#Aggregation\n",
    "'''\n",
    "aggregate = cos1_dis + cos2_dis + cos_graph_dis\n",
    "\n",
    "Matrix = aggregate\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f88c69e",
   "metadata": {},
   "source": [
    "### Jaccard Edge Type and length + df relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd8352d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph2:\n",
    "    # instance variables\n",
    "    def __init__(self, graph_list2, indexList):\n",
    "        # v is the number of nodes/vertices\n",
    "        self.time = 0\n",
    "        self.traversal_array = []\n",
    "        self.structural_array = []\n",
    "        #self.structural_array = []\n",
    "        self.graph_list = graph_list2\n",
    "        self.v = len(graph_list2)\n",
    "        self.indexList = indexList\n",
    "\n",
    "    # function for dfs\n",
    "    def dfs(self):\n",
    "        self.start_time = [-1]*self.v\n",
    "        self.end_time = [-1]*self.v\n",
    " \n",
    "        for node in range(self.v):\n",
    "            if self.start_time[node] == -1:\n",
    "                self.traverse_dfs(node)\n",
    "                \n",
    "        return self.structural_array\n",
    "        #print()\n",
    "        #print(\"DFS Traversal: \", self.traversal_array)\n",
    "        #print()\n",
    " \n",
    "    def traverse_dfs(self, node):\n",
    "        self.traversal_array.append(node)\n",
    "        # get the starting time\n",
    "        self.start_time[node] = self.time\n",
    "        self.time += 1\n",
    "        # traverse through the neighbours\n",
    "        for neighbour in self.graph_list[node]:\n",
    "\n",
    "            # when the neighbor was not yet visited\n",
    "            if self.start_time[neighbour] == -1:                \n",
    "                #self.structural_array[0][1] += 0\n",
    "                #self.structural_array.append('tree ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ')\n",
    "                self.structural_array.append('tree')\n",
    "                self.traverse_dfs(neighbour)\n",
    "                \n",
    "            # otherwise when the neighbour's visit is still ongoing:\n",
    "            elif self.end_time[neighbour] == -1:\n",
    "                if node == neighbour:\n",
    "                    self.structural_array.append('back ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ' ' + str(1))\n",
    "                    #self.structural_array.append([str(1)+'b'])\n",
    "                \n",
    "                elif node in self.graph_list[neighbour]:\n",
    "                    self.structural_array.append('back ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ' ' + str(2))\n",
    "                    #self.structural_array.append(str(2)+'b')\n",
    "                    \n",
    "                else:\n",
    "                    x = bfs_4(self.graph_list, neighbour, node)\n",
    "                    self.structural_array.append('back ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ' ' + str(x+1))\n",
    "                    #self.structural_array.append(str(x+1)+'b')\n",
    "                \n",
    "            # otherwise when the neighbour's visit started before the current node's visit:\n",
    "            elif self.start_time[node] < self.start_time[neighbour]:\n",
    "                graph_list_copy = copy.deepcopy(self.graph_list)\n",
    "                graph_list_copy[node].remove(neighbour)\n",
    "                y = bfs_4(graph_list_copy, node, neighbour)\n",
    "                self.structural_array.append('forward ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ' ' + str(y-1))\n",
    "                #self.structural_array.extend((y-1)*['forward']) # -1 to exclude one edge: (A:B,C;B:C;C:[]) ...the dist A --> C is 2 without forward edge, but we are skipping only one activity\n",
    "                #self.structural_array.append(str(y-1)+'f')\n",
    "                \n",
    "            else:\n",
    "                #Possibly first check, whether two nodes connected by cross-type have identical parent\n",
    "                numberSkips, numberCross = common_ancestors(self.graph_list, node, neighbour)\n",
    "                #self.structural_array.append('forward ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ' ' + str(numberSkips))\n",
    "                self.structural_array.append('cross ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ' ' + str(numberCross))\n",
    "                #self.structural_array.append(str(numberSkips)+'f')\n",
    "                #self.structural_array.append(str(numberCross)+'c')\n",
    "    \n",
    "        # Indentation corrected:\n",
    "        self.end_time[node] = self.time\n",
    "        self.time += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa23545",
   "metadata": {},
   "outputs": [],
   "source": [
    "logVar[\"int_strucLengthList3\"] = logVar.apply(lambda x: Graph2(x.int_adjList, x.indexList).dfs(), axis =1)\n",
    "#logVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee499fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jacc similarity based on edge types\n",
    "\n",
    "jacc_graph = matrix_calc(logVar[\"int_strucLengthList3\"],jaccard_similarity)\n",
    "results(jacc_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae80e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jacc sim based on edge types\n",
    "agg_jacc = Jacc1_dis + Jacc2_dis + jacc_graph\n",
    "results(agg_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b24af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23360253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e00cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logVar[\"int_strucLengthList4\"] = logVar.apply(lambda x: Graph2(x.int_adjList, x.indexList).dfs(), axis =1)\n",
    "#logVar[\"relFrequVec3\"] = logVar[\"int_strucLengthList3\"].apply(lambda x: createVector(x))\n",
    "#logVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5aa8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ListChar = list(logVar[\"int_strucLengthList4\"])\n",
    "\n",
    "#To avoid \"division by zero\" error\n",
    "for i in range(len(ListChar)):\n",
    "    if len(ListChar[i]) == 0:\n",
    "        ListChar[i].append('NaN')\n",
    "\n",
    "n = len(ListChar)\n",
    "dist_matrix = np.zeros((n,n))    # initialize distance matrix to a square of zeros\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = jaccard_similarity(ListChar[i], ListChar[j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]       # for the symmetric part, no computation\n",
    "        \n",
    "jacc_graph_dis2 = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a16019bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.21999999999999992\n",
      "P@10: 0.20314285714285715\n",
      "Tri:  tensor(0.1529)\n",
      "Sil:  -0.23659391430012866\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Matrix = jacc_graph_dis2\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ecfadad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.6485714285714285\n",
      "P@10: 0.4411428571428571\n",
      "Tri:  tensor(0.5209)\n",
      "Sil:  -0.04919421021766112\n"
     ]
    }
   ],
   "source": [
    "#Aggregation\n",
    "'''\n",
    "aggregate = jacc1_dis + jacc2_dis + jacc_graph_dis2\n",
    "\n",
    "\n",
    "Matrix = aggregate\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b9c11b",
   "metadata": {},
   "source": [
    "## Eventually Follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ee928c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial distance between strings\n",
    "\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "def distanceSpatial(traceString, char1, char2):\n",
    "    positions_letter1 = [pos for pos, char in enumerate(traceString) if char == char1]\n",
    "    positions_letter2 = [pos for pos, char in enumerate(traceString) if char == char2]\n",
    "    \n",
    "    distList = []\n",
    "    \n",
    "\n",
    "    for i in range(len(positions_letter1)):\n",
    "        for j in range(len(positions_letter2)):\n",
    "            dist = positions_letter2[j] - positions_letter1[i]\n",
    "            if dist > 0:\n",
    "                    #print(dist)\n",
    "                distList.append(dist)\n",
    "                    \n",
    "    \n",
    "    if not distList: #distList.append(0) #in the case the char1 is after char2 asign dist 0, i.e. char2 cannot be reached from char1\n",
    "        return 0\n",
    "    else:\n",
    "        return 1/min(distList)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def commonDistance(trace1, trace2):\n",
    "    \n",
    "    commonSet = set(trace1) & set(trace2)\n",
    "\n",
    "    commonList = list(commonSet)\n",
    "    commonList.sort()\n",
    "    #print(commonList)\n",
    "\n",
    "    n = len(commonSet)\n",
    "    dist_matrix1 = np.zeros((n,n))\n",
    "    dist_matrix2 = np.zeros((n,n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            dist_matrix1[i,j] = distanceSpatial(trace1, commonList[i], commonList[j])\n",
    "        \n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            dist_matrix2[i,j] = distanceSpatial(trace2, commonList[i], commonList[j])\n",
    "    \n",
    "    #print(dist_matrix1, dist_matrix2)\n",
    "    return distance.cosine(dist_matrix1.ravel(), dist_matrix2.ravel())\n",
    "\n",
    "\n",
    "\n",
    "#x = 'ABCDEF'\n",
    "#y = 'ABCDEBCDEBCDEF'\n",
    "#z = 'ABCDEBCDEF'\n",
    "#print(dist_matrix)\n",
    "#distanceSpatial(x, 'A', 'E')\n",
    "#listVec = logVar[\"strings\"]\n",
    "#x= listVec[0]\n",
    "#y= listVec[1]\n",
    "#commonDistance(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix_evFollows = matrix_calc(logVar[\"strings\"],commonDistance)\n",
    "agg_evFollows = 0.7*dist_matrix_evFollows + 0.3*cos1_dis \n",
    "results(agg_evFollows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6654ae4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\la1949\\Anaconda3\\envs\\pm4py\\lib\\site-packages\\scipy\\spatial\\distance.py:636: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "#Calculate cosine similarity based on Spatial distance\n",
    "'''\n",
    "listVec = logVar[\"strings\"]\n",
    "\n",
    "n = len(listVec)\n",
    "dist_matrix = np.zeros((n,n))    # initialize distance matrix to a square of zeros\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        #print(listVec[i], listVec[j])\n",
    "        dist_matrix[i,j] = commonDistance(listVec[i], listVec[j])\n",
    "        #print(dist_matrix[i,j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]       # for the symmetric part, no computation\n",
    "        \n",
    "dist_matrix_evFollow = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa6371ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.46571428571428564\n",
      "P@10: 0.3588571428571428\n",
      "Tri:  tensor(0.5255)\n",
      "Sil:  -0.044550543753551164\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "aggregate = 0.7*dist_matrix_evFollow + 0.3*cos1_dis \n",
    "\n",
    "Matrix = aggregate\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f580e6ec",
   "metadata": {},
   "source": [
    "## Maximal Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3385f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from suffix_tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree.maximal_repeats\n",
    "def maxRepeat(tree):\n",
    "    mrList=[]\n",
    "    for C, path in sorted(tree.maximal_repeats()):\n",
    "        mrList.append(str(path))\n",
    "    return mrList\n",
    "\n",
    "#test_tree = Tree({\"A\": \"aaacdcdcbedbccbadbdebdc\"})\n",
    "#maxRepeat(test_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f5eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create vector based on maximal repeats\n",
    "logVar[\"mrList\"] = logVar[\"strings\"].apply(lambda x: maxRepeat(Tree({\"A\": x})))\n",
    "logVar[\"mrVector\"] = logVar[\"mrList\"].apply(lambda x: createVector(tuple(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e6b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on maxR\n",
    "\n",
    "cos_mr = matrix_calc(logVar[\"mrVector\"],cosineDist)\n",
    "results(cos_mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dc8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean distance based on maxR\n",
    "\n",
    "euc_mr = matrix_calc(logVar[\"mrVector\"],euclidDist)\n",
    "results(euc_mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e30fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jaccard similarity based on maxR\n",
    "\n",
    "jacc_mr = matrix_calc(logVar[\"mrList\"],jaccard_similarity)\n",
    "results(jacc_mr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ed00",
   "metadata": {},
   "source": [
    "## Optimal Alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import pairwise2\n",
    "import math\n",
    "\n",
    "\n",
    "# Define sequences\n",
    "#seq1 = \"ACCGTTTTT\"\n",
    "#seq2 = \"ACG\"\n",
    "\n",
    "# Perform global alignment with scoring:\n",
    "# match = +2, mismatch = -1, gap open = -2, gap extend = 0\n",
    "#alignments = pairwise2.align.globalms(seq1, seq2, 2, -1, -2, 0)\n",
    "\n",
    "#alignments\n",
    "#score --> alignments[0][2]\n",
    "\n",
    "def optAlign1(string1, string2):\n",
    "    alignments = pairwise2.align.globalms(string1, string2, 1, 0, 0, 0)    \n",
    "    return 1 - (alignments[0][2]/max(len(string1),len(string2)))\n",
    "\n",
    "\n",
    "def optAlign2(string1, string2):\n",
    "    alignments = pairwise2.align.globalms(string1, string2, 2, -1, -2, 0)    \n",
    "    return 1 / (1 + math.exp(0.05*alignments[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f88066",
   "metadata": {},
   "outputs": [],
   "source": [
    "Align_dis1 = matrix_calc(logVar[\"strings\"],optAlign1)\n",
    "results(Align_dis1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3187139",
   "metadata": {},
   "outputs": [],
   "source": [
    "Align_dis2 = matrix_calc(logVar[\"strings\"],optAlign2)\n",
    "results(Align_dis2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

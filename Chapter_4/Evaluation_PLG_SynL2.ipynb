{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57d097ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pm4py\n",
    "import numpy as np\n",
    "#from scipy.stats import mannwhitneyu\n",
    "#import collections\n",
    "#from statistics import mean\n",
    "#from statistics import median\n",
    "from collections import defaultdict\n",
    "from Levenshtein import distance\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn import metrics\n",
    "#from sklearn.metrics.cluster import homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score, adjusted_mutual_info_score, silhouette_score\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "841f7107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 300/300 [00:00<00:00, 1609.86it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 300/300 [00:00<00:00, 1622.05it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 300/300 [00:00<00:00, 1681.32it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 300/300 [00:00<00:00, 979.01it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 150/150 [00:00<00:00, 308.73it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 150/150 [00:00<00:00, 570.14it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 150/150 [00:00<00:00, 380.09it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 150/150 [00:00<00:00, 886.00it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 150/150 [00:00<00:00, 1140.22it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 150/150 [00:00<00:00, 1086.35it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 150/150 [00:00<00:00, 787.23it/s] \n",
      "parsing log, completed traces :: 100%|██████████| 150/150 [00:00<00:00, 1293.80it/s]\n"
     ]
    }
   ],
   "source": [
    "log1 = pm4py.read.read_xes(\"SynLogs\\Choice_Long_NEW.gz\")\n",
    "log1[\"case:concept:name\"] = log1[\"case:concept:name\"] + 'C1'\n",
    "log1['type'] = 'C1'\n",
    "\n",
    "log2 = pm4py.read.read_xes(\"SynLogs\\Choice_Short_NEW.gz\")\n",
    "log2[\"case:concept:name\"] = log2[\"case:concept:name\"] + 'C2'\n",
    "log2['type'] = 'C2'\n",
    "\n",
    "\n",
    "log7 = pm4py.read.read_xes(\"SynLogs\\Choice_Long_X_NEW.gz\")\n",
    "log7[\"case:concept:name\"] = log7[\"case:concept:name\"] + 'C3'\n",
    "log7['type'] = 'C3'\n",
    "\n",
    "log8 = pm4py.read.read_xes(\"SynLogs\\Choice_Short_X_NEW.gz\")\n",
    "log8[\"case:concept:name\"] = log8[\"case:concept:name\"] + 'C4'\n",
    "log8['type'] = 'C4'\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "log3 = pm4py.read.read_xes(\"SynLogs\\Loops_Long.xes\")\n",
    "log3[\"case:concept:name\"] = log3[\"case:concept:name\"] + 'L1'\n",
    "log3['type'] = 'L1'\n",
    "\n",
    "\n",
    "log4 = pm4py.read.read_xes(\"SynLogs\\Loops_Short.xes\")\n",
    "log4[\"case:concept:name\"] = log4[\"case:concept:name\"] + 'L2'\n",
    "log4['type'] = 'L2'\n",
    "\n",
    "\n",
    "log9 = pm4py.read.read_xes(\"SynLogs\\Loops_Long_X.xes\")\n",
    "log9[\"case:concept:name\"] = log9[\"case:concept:name\"] + 'L3'\n",
    "log9['type'] = 'L3'\n",
    "\n",
    "\n",
    "log10 = pm4py.read.read_xes(\"SynLogs\\Loops_Short_X.xes\")\n",
    "log10[\"case:concept:name\"] = log10[\"case:concept:name\"] + 'L4'\n",
    "log10['type'] = 'L4'\n",
    "\n",
    "###\n",
    "\n",
    "log5 = pm4py.read.read_xes(\"SynLogs\\Skips_Long.xes\")\n",
    "log5[\"case:concept:name\"] = log5[\"case:concept:name\"] + 'S1'\n",
    "log5['type'] = 'S1'\n",
    "\n",
    "\n",
    "log6 = pm4py.read.read_xes(\"SynLogs\\Skips_Short.xes\")\n",
    "log6[\"case:concept:name\"] = log6[\"case:concept:name\"] + 'S2'\n",
    "log6['type'] = 'S2'\n",
    "\n",
    "log11 = pm4py.read.read_xes(\"SynLogs\\Skips_Long_X.xes\")\n",
    "log11[\"case:concept:name\"] = log11[\"case:concept:name\"] + 'S3'\n",
    "log11['type'] = 'S3'\n",
    "\n",
    "\n",
    "log12 = pm4py.read.read_xes(\"SynLogs\\Skips_Short_X.xes\")\n",
    "log12[\"case:concept:name\"] = log12[\"case:concept:name\"] + 'S4'\n",
    "log12['type'] = 'S4'\n",
    "\n",
    "\n",
    "log = pd.concat([log1, log2, log3, log4, log5, log6, log11, log12, log10, log9, log8, log7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef48af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'tabName_element' column\n",
    "log['activity'] = le.fit_transform(log['concept:name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d64e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create trace log\n",
    "logVar = log.groupby(['case:concept:name'])['activity'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9eb23b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logType = log.groupby(['case:concept:name'])['type'].apply(list).reset_index()\n",
    "logType['type'] = logType['type'].apply(lambda x: set(x))\n",
    "logType['type'] = logType['type'].apply(lambda x: ''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67c5761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logVar0 = pd.merge(logVar, logType, on='case:concept:name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "382bdb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>activity</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case_0C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 3, 4, 7]</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case_0C2</td>\n",
       "      <td>[0, 1, 5, 6, 7, 0, 4, 5, 6, 7]</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case_0C3</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case_0C4</td>\n",
       "      <td>[8, 9, 13, 14, 15, 8, 10, 13, 14, 15]</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case_0L1</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...</td>\n",
       "      <td>L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>case_9L4</td>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 8, 9, 10, 11, 1...</td>\n",
       "      <td>L4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>case_9S1</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 0, 5, 6, 7]</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>case_9S2</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 0, 3, 4, 7, 0, 3, 4, ...</td>\n",
       "      <td>S2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>case_9S3</td>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 8, 14, 15]</td>\n",
       "      <td>S3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>case_9S4</td>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 8, 10, 11, 12, ...</td>\n",
       "      <td>S4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     case:concept:name                                           activity type\n",
       "0             case_0C1                           [0, 1, 2, 7, 0, 3, 4, 7]   C1\n",
       "1             case_0C2                     [0, 1, 5, 6, 7, 0, 4, 5, 6, 7]   C2\n",
       "2             case_0C3  [8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...   C3\n",
       "3             case_0C4              [8, 9, 13, 14, 15, 8, 10, 13, 14, 15]   C4\n",
       "4             case_0L1  [0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...   L1\n",
       "...                ...                                                ...  ...\n",
       "2395          case_9L4  [8, 9, 10, 11, 12, 13, 14, 15, 8, 9, 10, 11, 1...   L4\n",
       "2396          case_9S1               [0, 1, 2, 3, 4, 5, 6, 7, 0, 5, 6, 7]   S1\n",
       "2397          case_9S2  [0, 1, 2, 3, 4, 5, 6, 7, 0, 3, 4, 7, 0, 3, 4, ...   S2\n",
       "2398          case_9S3          [8, 9, 10, 11, 12, 13, 14, 15, 8, 14, 15]   S3\n",
       "2399          case_9S4  [8, 9, 10, 11, 12, 13, 14, 15, 8, 10, 11, 12, ...   S4\n",
       "\n",
       "[2400 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVar0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8099716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1    300\n",
       "C2    300\n",
       "C3    300\n",
       "C4    300\n",
       "L1    150\n",
       "L2    150\n",
       "L3    150\n",
       "L4    150\n",
       "S1    150\n",
       "S2    150\n",
       "S3    150\n",
       "S4    150\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVar0['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2df654a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>activity</th>\n",
       "      <th>type</th>\n",
       "      <th>act_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case_0C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 3, 4, 7]</td>\n",
       "      <td>C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 3, 4, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case_0C2</td>\n",
       "      <td>[0, 1, 5, 6, 7, 0, 4, 5, 6, 7]</td>\n",
       "      <td>C2</td>\n",
       "      <td>[0, 1, 5, 6, 7, 0, 4, 5, 6, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case_0C3</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...</td>\n",
       "      <td>C3</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case_0C4</td>\n",
       "      <td>[8, 9, 13, 14, 15, 8, 10, 13, 14, 15]</td>\n",
       "      <td>C4</td>\n",
       "      <td>[8, 9, 13, 14, 15, 8, 10, 13, 14, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case_0L1</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...</td>\n",
       "      <td>L1</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>case_9C4</td>\n",
       "      <td>[8, 9, 13, 14, 15, 8, 11, 13, 14, 15, 8, 12, 1...</td>\n",
       "      <td>C4</td>\n",
       "      <td>[8, 9, 13, 14, 15, 8, 11, 13, 14, 15, 8, 12, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>case_9L1</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...</td>\n",
       "      <td>L1</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>case_9L2</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...</td>\n",
       "      <td>L2</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>case_9L3</td>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 8, 9, 10, 11, 1...</td>\n",
       "      <td>L3</td>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 8, 9, 10, 11, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>case_9L4</td>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 8, 9, 10, 11, 1...</td>\n",
       "      <td>L4</td>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 8, 9, 10, 11, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    case:concept:name                                           activity type  \\\n",
       "0            case_0C1                           [0, 1, 2, 7, 0, 3, 4, 7]   C1   \n",
       "1            case_0C2                     [0, 1, 5, 6, 7, 0, 4, 5, 6, 7]   C2   \n",
       "2            case_0C3  [8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...   C3   \n",
       "3            case_0C4              [8, 9, 13, 14, 15, 8, 10, 13, 14, 15]   C4   \n",
       "4            case_0L1  [0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...   L1   \n",
       "..                ...                                                ...  ...   \n",
       "959          case_9C4  [8, 9, 13, 14, 15, 8, 11, 13, 14, 15, 8, 12, 1...   C4   \n",
       "960          case_9L1  [0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...   L1   \n",
       "961          case_9L2  [0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...   L2   \n",
       "962          case_9L3  [8, 9, 10, 11, 12, 13, 14, 15, 8, 9, 10, 11, 1...   L3   \n",
       "963          case_9L4  [8, 9, 10, 11, 12, 13, 14, 15, 8, 9, 10, 11, 1...   L4   \n",
       "\n",
       "                                               act_str  \n",
       "0                             [0, 1, 2, 7, 0, 3, 4, 7]  \n",
       "1                       [0, 1, 5, 6, 7, 0, 4, 5, 6, 7]  \n",
       "2    [8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...  \n",
       "3                [8, 9, 13, 14, 15, 8, 10, 13, 14, 15]  \n",
       "4    [0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...  \n",
       "..                                                 ...  \n",
       "959  [8, 9, 13, 14, 15, 8, 11, 13, 14, 15, 8, 12, 1...  \n",
       "960  [0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...  \n",
       "961  [0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, ...  \n",
       "962  [8, 9, 10, 11, 12, 13, 14, 15, 8, 9, 10, 11, 1...  \n",
       "963  [8, 9, 10, 11, 12, 13, 14, 15, 8, 9, 10, 11, 1...  \n",
       "\n",
       "[964 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Derive set of unique trace variants + count\n",
    "logVar0[\"act_str\"] = logVar0[\"activity\"].apply(lambda x: str(x))\n",
    "#logVar0['Count'] = logVar0.groupby(['act_str'])['activity'].transform('count')\n",
    "logVar0 = logVar0.drop_duplicates(subset=['act_str'], keep='first')\n",
    "logVar0 = logVar0.reset_index(drop=True)\n",
    "logVar0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38adad88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L1    132\n",
       "L2    124\n",
       "L3    123\n",
       "L4    121\n",
       "S4     79\n",
       "S2     75\n",
       "C2     63\n",
       "C4     60\n",
       "S3     59\n",
       "S1     51\n",
       "C1     42\n",
       "C3     35\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVar0['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65eeb7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify traces according to edge types + long/short\n",
    "n=25\n",
    "\n",
    "logVar1 = logVar0.loc[logVar0['type'] == 'C1'] #Choice_Long\n",
    "logVar1 = logVar1.sample(n)\n",
    "logVar1['type'] = 'C1'\n",
    "\n",
    "logVar7 = logVar0.loc[logVar0['type'] == 'C3'] #Choice-Long_X\n",
    "logVar7 = logVar7.sample(n)\n",
    "logVar7['type'] = 'C1'\n",
    "\n",
    "\n",
    "\n",
    "logVar2 = logVar0.loc[logVar0['type'] == 'C2'] #Choice_Short\n",
    "logVar2 = logVar2.sample(n)\n",
    "logVar2['type'] = 'C2'\n",
    "\n",
    "logVar8 = logVar0.loc[logVar0['type'] == 'C4'] #Choice_Short_X\n",
    "logVar8 = logVar8.sample(n)\n",
    "logVar8['type'] = 'C2'\n",
    "\n",
    "\n",
    "\n",
    "logVar3 = logVar0.loc[logVar0['type'] == 'L1'] #Loop_Long\n",
    "logVar3 = logVar3.sample(n)\n",
    "logVar3['type'] = 'L1'\n",
    "\n",
    "logVar9 = logVar0.loc[logVar0['type'] == 'L3'] #Loop_Long_X\n",
    "logVar9 = logVar9.sample(n)\n",
    "logVar9['type'] = 'L1'\n",
    "\n",
    "\n",
    "\n",
    "logVar4 = logVar0.loc[logVar0['type'] == 'L2'] #Loop_Short\n",
    "logVar4 = logVar4.sample(n)\n",
    "logVar4['type'] = 'L2'\n",
    "\n",
    "logVar10 = logVar0.loc[logVar0['type'] == 'L4'] #Loop_Short_X\n",
    "logVar10 = logVar10.sample(n)\n",
    "logVar10['type'] = 'L2'\n",
    "\n",
    "\n",
    "\n",
    "logVar5 = logVar0.loc[logVar0['type'] == 'S1'] #Skip_Long\n",
    "logVar5 = logVar5.sample(n)\n",
    "logVar5['type'] = 'S1'\n",
    "\n",
    "logVar11 = logVar0.loc[logVar0['type'] == 'S3'] #Skip_Long_X\n",
    "logVar11 = logVar11.sample(n)\n",
    "logVar11['type'] = 'S1'\n",
    "\n",
    "\n",
    "\n",
    "logVar6 = logVar0.loc[logVar0['type'] == 'S2'] #Skip_Short\n",
    "logVar6 = logVar6.sample(n)\n",
    "logVar6['type'] = 'S2'\n",
    "\n",
    "logVar12 = logVar0.loc[logVar0['type'] == 'S4'] #Skip_Short_X\n",
    "logVar12 = logVar12.sample(n)\n",
    "logVar12['type'] = 'S2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df75adf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>activity</th>\n",
       "      <th>type</th>\n",
       "      <th>act_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>case_118C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7]</td>\n",
       "      <td>C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "      <td>case_110C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7, 0, 3, 4, ...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7, 0, 3, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>case_10C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 3, 4, 7, 0, 5, 6, 7, 0, 3, 4, ...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 3, 4, 7, 0, 5, 6, 7, 0, 3, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230</td>\n",
       "      <td>case_126C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 3, 4, 7]</td>\n",
       "      <td>C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 3, 4, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>371</td>\n",
       "      <td>case_145C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 5, 6, ...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 5, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>442</td>\n",
       "      <td>case_187C3</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>540</td>\n",
       "      <td>case_277C3</td>\n",
       "      <td>[8, 9, 10, 15, 8, 11, 12, 15, 8, 11, 12, 15, 8...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[8, 9, 10, 15, 8, 11, 12, 15, 8, 11, 12, 15, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>35</td>\n",
       "      <td>case_102C3</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15]</td>\n",
       "      <td>C1</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>46</td>\n",
       "      <td>case_103C3</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 13, 14, 15, 8...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 13, 14, 15, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>192</td>\n",
       "      <td>case_120C3</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index case:concept:name  \\\n",
       "0      171        case_118C1   \n",
       "1      114        case_110C1   \n",
       "2      104         case_10C1   \n",
       "3      230        case_126C1   \n",
       "4      371        case_145C1   \n",
       "..     ...               ...   \n",
       "295    442        case_187C3   \n",
       "296    540        case_277C3   \n",
       "297     35        case_102C3   \n",
       "298     46        case_103C3   \n",
       "299    192        case_120C3   \n",
       "\n",
       "                                              activity type  \\\n",
       "0                 [0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7]   C1   \n",
       "1    [0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7, 0, 3, 4, ...   C1   \n",
       "2    [0, 1, 2, 7, 0, 3, 4, 7, 0, 5, 6, 7, 0, 3, 4, ...   C1   \n",
       "3     [0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 3, 4, 7]   C1   \n",
       "4    [0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 5, 6, ...   C1   \n",
       "..                                                 ...  ...   \n",
       "295  [8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...   C1   \n",
       "296  [8, 9, 10, 15, 8, 11, 12, 15, 8, 11, 12, 15, 8...   C1   \n",
       "297                      [8, 9, 10, 15, 8, 13, 14, 15]   C1   \n",
       "298  [8, 9, 10, 15, 8, 13, 14, 15, 8, 13, 14, 15, 8...   C1   \n",
       "299  [8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...   C1   \n",
       "\n",
       "                                               act_str  \n",
       "0                 [0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7]  \n",
       "1    [0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7, 0, 3, 4, ...  \n",
       "2    [0, 1, 2, 7, 0, 3, 4, 7, 0, 5, 6, 7, 0, 3, 4, ...  \n",
       "3     [0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 3, 4, 7]  \n",
       "4    [0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 5, 6, ...  \n",
       "..                                                 ...  \n",
       "295  [8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...  \n",
       "296  [8, 9, 10, 15, 8, 11, 12, 15, 8, 11, 12, 15, 8...  \n",
       "297                      [8, 9, 10, 15, 8, 13, 14, 15]  \n",
       "298  [8, 9, 10, 15, 8, 13, 14, 15, 8, 13, 14, 15, 8...  \n",
       "299  [8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...  \n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVar = pd.concat([logVar1, logVar2, logVar3, logVar4, logVar5, logVar6, logVar11, logVar12, logVar10, logVar9, logVar8, logVar7]).reset_index()\n",
    "logVar\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "717c5345",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1    50\n",
       "C2    50\n",
       "L1    50\n",
       "L2    50\n",
       "S1    50\n",
       "S2    50\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVar['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04b06c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "logVar.to_csv('logVar_PLG_SynL2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62266631",
   "metadata": {},
   "outputs": [],
   "source": [
    "logVar = pd.read_csv('logVar_PLG_SynL2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ad2d53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>activity</th>\n",
       "      <th>type</th>\n",
       "      <th>act_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>case_118C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7]</td>\n",
       "      <td>C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "      <td>case_110C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7, 0, 3, 4, ...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7, 0, 3, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>case_10C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 3, 4, 7, 0, 5, 6, 7, 0, 3, 4, ...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 3, 4, 7, 0, 5, 6, 7, 0, 3, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230</td>\n",
       "      <td>case_126C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 3, 4, 7]</td>\n",
       "      <td>C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 3, 4, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>371</td>\n",
       "      <td>case_145C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 5, 6, ...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 5, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>442</td>\n",
       "      <td>case_187C3</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>540</td>\n",
       "      <td>case_277C3</td>\n",
       "      <td>[8, 9, 10, 15, 8, 11, 12, 15, 8, 11, 12, 15, 8...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[8, 9, 10, 15, 8, 11, 12, 15, 8, 11, 12, 15, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>35</td>\n",
       "      <td>case_102C3</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15]</td>\n",
       "      <td>C1</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>46</td>\n",
       "      <td>case_103C3</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 13, 14, 15, 8...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 13, 14, 15, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>192</td>\n",
       "      <td>case_120C3</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...</td>\n",
       "      <td>C1</td>\n",
       "      <td>[8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index case:concept:name  \\\n",
       "0      171        case_118C1   \n",
       "1      114        case_110C1   \n",
       "2      104         case_10C1   \n",
       "3      230        case_126C1   \n",
       "4      371        case_145C1   \n",
       "..     ...               ...   \n",
       "295    442        case_187C3   \n",
       "296    540        case_277C3   \n",
       "297     35        case_102C3   \n",
       "298     46        case_103C3   \n",
       "299    192        case_120C3   \n",
       "\n",
       "                                              activity type  \\\n",
       "0                 [0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7]   C1   \n",
       "1    [0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7, 0, 3, 4, ...   C1   \n",
       "2    [0, 1, 2, 7, 0, 3, 4, 7, 0, 5, 6, 7, 0, 3, 4, ...   C1   \n",
       "3     [0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 3, 4, 7]   C1   \n",
       "4    [0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 5, 6, ...   C1   \n",
       "..                                                 ...  ...   \n",
       "295  [8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...   C1   \n",
       "296  [8, 9, 10, 15, 8, 11, 12, 15, 8, 11, 12, 15, 8...   C1   \n",
       "297                      [8, 9, 10, 15, 8, 13, 14, 15]   C1   \n",
       "298  [8, 9, 10, 15, 8, 13, 14, 15, 8, 13, 14, 15, 8...   C1   \n",
       "299  [8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...   C1   \n",
       "\n",
       "                                               act_str  \n",
       "0                 [0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7]  \n",
       "1    [0, 1, 2, 7, 0, 5, 6, 7, 0, 3, 4, 7, 0, 3, 4, ...  \n",
       "2    [0, 1, 2, 7, 0, 3, 4, 7, 0, 5, 6, 7, 0, 3, 4, ...  \n",
       "3     [0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 3, 4, 7]  \n",
       "4    [0, 1, 2, 7, 0, 5, 6, 7, 0, 5, 6, 7, 0, 5, 6, ...  \n",
       "..                                                 ...  \n",
       "295  [8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...  \n",
       "296  [8, 9, 10, 15, 8, 11, 12, 15, 8, 11, 12, 15, 8...  \n",
       "297                      [8, 9, 10, 15, 8, 13, 14, 15]  \n",
       "298  [8, 9, 10, 15, 8, 13, 14, 15, 8, 13, 14, 15, 8...  \n",
       "299  [8, 9, 10, 15, 8, 13, 14, 15, 8, 11, 12, 15, 8...  \n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cac2a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "logVar[\"activity\"] = logVar[\"activity\"].apply(lambda x: ast.literal_eval(x))\n",
    "logVar[\"c:n_chr\"] = logVar[\"activity\"].apply(lambda x: [chr(int(i)) for i in x])\n",
    "logVar[\"strings\"] = logVar[\"c:n_chr\"].apply(lambda x: ''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1090460b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVar[\"length\"] = logVar[\"activity\"].apply(lambda x: len(x))\n",
    "logVar['length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e6821bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logVar['length'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07bf24c",
   "metadata": {},
   "source": [
    "## Ground truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52b2134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "#Create dictionary with true labels\n",
    "logVar['class'] = le.fit_transform(logVar['type'])\n",
    "labelDict1 = logVar['class'].to_dict()\n",
    "#labelDict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1b48b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_calc(features, distance):\n",
    "    n = len(features)\n",
    "    dist_matrix = np.zeros((n,n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            dist_matrix[i,j] = distance(features[i], features[j])\n",
    "            dist_matrix[j,i] = dist_matrix[i,j]\n",
    "    \n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97389b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(DistMatrix):\n",
    "    print('NN:   ' + str(NearestNeighbor(DistMatrix, labelDict1)))\n",
    "    print('P@10: ' + str(PrecisionAtK(DistMatrix, labelDict1, 10)))\n",
    "\n",
    "    triplet = BatchAllTtripletLoss()\n",
    "    print('Tri:  ' + str(triplet.forward(DistMatrix,labelDict1)))\n",
    "    print('Sil:  ' + str(Silhouette(DistMatrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0863e5",
   "metadata": {},
   "source": [
    "## Evaluation based on Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8407d2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx = np.array([[ 0, 12,  8, 10, 12],\\n       [5,  0,  9, 14, 17],\\n       [ 8,  9,  0, 12, 10],\\n       [ 8,  9,  1, 0, 10],\\n       [ 8,  9,  5, 4, 0]])\\n\\nlabelDict2 = {0:1,1:2,2:1,3:3,4:3}\\nNearestNeighbor(x, labelDict2)\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def NearestNeighbor(matrix, labelDict):\n",
    "    \n",
    "    clusterLabel = set(labelDict.values())\n",
    "    clusterMeasuredCount = dict.fromkeys(list(clusterLabel), 0)\n",
    "    \n",
    "    for i in range(len(matrix)):\n",
    "        #delete 0 in array matrix[i] for distance between (i,i)\n",
    "        x = np.delete(matrix[i], i) \n",
    "        #identify min distance/value in array\n",
    "        y = min(x)\n",
    "        \n",
    "        #identify position of y AND select first position/pair appearing in the array in case there are muliple pairs with identical min distance\n",
    "        nearestNeighbor = np.where(x == y)[0] #problem if multiple positions??\n",
    "        nearestNeighbor = int(nearestNeighbor[0])\n",
    "        \n",
    "        #true Label for i\n",
    "        trueLabel = labelDict[i]\n",
    "        \n",
    "        #for label comparison add +1 to dict position if position occurs after i (because of the deletion of 0 at the beginning)\n",
    "        if nearestNeighbor >= i:\n",
    "            if trueLabel == labelDict[nearestNeighbor + 1]:\n",
    "                clusterMeasuredCount[trueLabel] += 1         \n",
    "        else:\n",
    "            if trueLabel == labelDict[nearestNeighbor]:\n",
    "                clusterMeasuredCount[trueLabel] += 1\n",
    "    \n",
    "    #Count the (true) number of traces per label/attribute\n",
    "    clusterTrueCount = {}\n",
    "    for i in clusterLabel:\n",
    "        clusterTrueCount[i] = list(labelDict.values()).count(i)\n",
    "    \n",
    "    #Divide number of nearest neighbours with identical label by the respective (true number) of traces with this label\n",
    "    metric = 0\n",
    "    for i in clusterLabel:\n",
    "        metric += clusterMeasuredCount[i] / clusterTrueCount[i]\n",
    "        \n",
    "    #print(clusterMeasuredCount, clusterTrueCount, metric)\n",
    "    \n",
    "    #print(clusterMeasuredCount)\n",
    "    #print(clusterTrueCount)\n",
    "    #print(clusterLabel)\n",
    "    #print(metric)\n",
    "    return metric / len(clusterLabel)\n",
    "\n",
    "\n",
    "'''\n",
    "x = np.array([[ 0, 12,  8, 10, 12],\n",
    "       [5,  0,  9, 14, 17],\n",
    "       [ 8,  9,  0, 12, 10],\n",
    "       [ 8,  9,  1, 0, 10],\n",
    "       [ 8,  9,  5, 4, 0]])\n",
    "\n",
    "labelDict2 = {0:1,1:2,2:1,3:3,4:3}\n",
    "NearestNeighbor(x, labelDict2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0aae66",
   "metadata": {},
   "source": [
    "## Evaluation based on Precision@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24a0d082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx3 = np.array([[ 0, 12,  8, 10, 12],\\n       [5,  0,  9, 14, 17],\\n       [ 8,  9,  0, 12, 10],\\n       [ 8,  9,  1, 0, 10],\\n       [ 4,  8,  4, 4, 0]]) # --> Issue: How to select NN when identical distance values !!!\\n\\nlabelDict3 = {0:1,1:2,2:1,3:3,4:3}\\nPrecisionAtK(x3, labelDict3, 2)\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_key_by_value(dictionary, value):\n",
    "    for key, val in dictionary.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "    #return None  # Return None if the value is not found in the dictionary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def PrecisionAtK(matrix, labelDict, k):\n",
    "    \n",
    "    clusterLabel = set(labelDict.values())\n",
    "    clusterMeasuredCount = dict.fromkeys(list(clusterLabel), 0)\n",
    "    \n",
    "    \n",
    "    for i in range(len(matrix)):\n",
    "        \n",
    "        #true Label for i\n",
    "        trueLabel = labelDict[i]\n",
    "\n",
    "        \n",
    "        #delete 0 in array matrix[i] for distance between (i,i)   \n",
    "        x = np.delete(matrix[i], i)\n",
    "        \n",
    "        #get all k minimum values\n",
    "        nnValues = []\n",
    "        for l in range(k):\n",
    "            y = min(x)\n",
    "            nnValues.append(y)\n",
    "            x = np.delete(x, np.where(x == y)[0][0])\n",
    "        \n",
    "        \n",
    "        #get location of minimum values\n",
    "        z = np.delete(matrix[i], i)\n",
    "        \n",
    "        #create dict from array with {position:value}\n",
    "        my_dict = {}\n",
    "        for m in range(len(z)):\n",
    "            my_dict[m] = z[m]\n",
    "        \n",
    "        key_list = []\n",
    "        for n in nnValues:\n",
    "            key = get_key_by_value(my_dict, n)\n",
    "            key_list.append(key)\n",
    "            del my_dict[key]\n",
    "        \n",
    "        for o in range(k):\n",
    "            position = list(key_list)[o]\n",
    "\n",
    "            if position >= i:\n",
    "                if trueLabel == labelDict[position + 1]:\n",
    "                    clusterMeasuredCount[trueLabel] += 1\n",
    "\n",
    "            else:\n",
    "                if trueLabel == labelDict[position]:\n",
    "                    clusterMeasuredCount[trueLabel] += 1\n",
    "\n",
    "            #transform array to dict\n",
    "            #get key value from dict\n",
    "            #compare label\n",
    "            #remove key+value from dict\n",
    "\n",
    "            #Need exception in case y == 0 ??\n",
    "            \n",
    "    \n",
    "    #Count the (true) number of traces per label/attribute\n",
    "    clusterTrueCount = {}\n",
    "    for i in clusterLabel:\n",
    "        clusterTrueCount[i] = list(labelDict.values()).count(i)\n",
    "    \n",
    "    #Divide number of nearest neighbours with identical label by the respective (true number) of traces with this label\n",
    "    metric = 0\n",
    "    for i in clusterLabel:\n",
    "        metric += clusterMeasuredCount[i] / k / clusterTrueCount[i]\n",
    "        \n",
    "    #print(clusterMeasuredCount, clusterTrueCount, metric)\n",
    "    \n",
    "    #print(clusterLabel)\n",
    "    #print(metric)\n",
    "    return metric / len(clusterLabel)\n",
    "\n",
    "\n",
    "'''\n",
    "x3 = np.array([[ 0, 12,  8, 10, 12],\n",
    "       [5,  0,  9, 14, 17],\n",
    "       [ 8,  9,  0, 12, 10],\n",
    "       [ 8,  9,  1, 0, 10],\n",
    "       [ 4,  8,  4, 4, 0]]) # --> Issue: How to select NN when identical distance values !!!\n",
    "\n",
    "labelDict3 = {0:1,1:2,2:1,3:3,4:3}\n",
    "PrecisionAtK(x3, labelDict3, 2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18183bf",
   "metadata": {},
   "source": [
    "## Triplet\n",
    "\n",
    "see: https://towardsdatascience.com/triplet-loss-advanced-intro-49a07b7d8905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b8138ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "836bd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_mask(labels):\n",
    "    \n",
    "    # step 1 - get a mask for distinct indices\n",
    "    ###print('labels', labels)\n",
    "    # shape: (batch_size, batch_size)\n",
    "    indices_equal = torch.eye(labels.size()[0], dtype=torch.bool, device=labels.device)\n",
    "    ###print('equal', indices_equal)\n",
    "    indices_not_equal = torch.logical_not(indices_equal)\n",
    "    ###print('not_equal', indices_not_equal)\n",
    "\n",
    "    # shape: (batch_size, batch_size, 1)\n",
    "    i_not_equal_j = indices_not_equal.unsqueeze(2)\n",
    "    ###print('i_not_j - unsqueeze2', i_not_equal_j)\n",
    "    # shape: (batch_size, 1, batch_size)\n",
    "    i_not_equal_k = indices_not_equal.unsqueeze(1)\n",
    "    ###print('i_not_k - unsqueeze1', i_not_equal_k)\n",
    "    # shape: (1, batch_size, batch_size)\n",
    "    j_not_equal_k = indices_not_equal.unsqueeze(0)\n",
    "    ###print('j_not_k - unsqueeze0', i_not_equal_k)\n",
    "    # Shape: (batch_size, batch_size, batch_size)\n",
    "    distinct_indices = torch.logical_and(torch.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "    ###print('distinct!!!!', distinct_indices)\n",
    "\n",
    "    # step 2 - get a mask for valid anchor-positive-negative triplets\n",
    "    # shape: (batch_size, batch_size)\n",
    "    labels_equal = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
    "    ###print('labels_equal', labels_equal)\n",
    "    # shape: (batch_size, batch_size, 1)\n",
    "    i_equal_j = labels_equal.unsqueeze(2)\n",
    "    ###print('i_equal_j', i_equal_j)\n",
    "    # shape: (batch_size, 1, batch_size)\n",
    "    i_equal_k = labels_equal.unsqueeze(1)\n",
    "    ###print('i_equal_k', i_equal_k)\n",
    "    # shape: (batch_size, batch_size, batch_size)\n",
    "    valid_indices = torch.logical_and(i_equal_j, torch.logical_not(i_equal_k))\n",
    "    ###print('valid_indices!!!', valid_indices)\n",
    "    \n",
    "\n",
    "    # step 3 - combine two masks\n",
    "    mask = torch.logical_and(distinct_indices, valid_indices)\n",
    "    ###print('mask!!', mask)\n",
    "    return mask\n",
    "\n",
    "    \"\"\"compute a mask for valid triplets\n",
    "    Args:\n",
    "        labels: Batch of integer labels. shape: (batch_size,)\n",
    "    Returns:\n",
    "        Mask tensor to indicate which triplets are actually valid. Shape: (batch_size, batch_size, batch_size)\n",
    "        A triplet is valid if:\n",
    "        `labels[i] == labels[j] and labels[i] != labels[k]`\n",
    "        and `i`, `j`, `k` are different.\n",
    "    \"\"\"\n",
    "    \n",
    "class custom_activation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(custom_activation, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x[x>0] = 1\n",
    "        x[x<=0] = 0\n",
    "        return x\n",
    "\n",
    "\n",
    "class BatchAllTtripletLoss(nn.Module):\n",
    "  \"\"\"Uses all valid triplets to compute Triplet loss\n",
    "\n",
    "  Args:\n",
    "    margin: Margin value in the Triplet Loss equation\n",
    "  \"\"\"\n",
    "  def __init__(self, margin=0): #default margin = 0\n",
    "    super().__init__()\n",
    "    self.margin = margin\n",
    "    self.relu = nn.ReLU() #new\n",
    "    self.custom = custom_activation()\n",
    "    \n",
    "  def forward(self, distance_matrix, labels):\n",
    "    \"\"\"computes loss value.\n",
    "\n",
    "    Args:\n",
    "      embeddings: Batch of embeddings, e.g., output of the encoder. shape: (batch_size, embedding_dim)\n",
    "      labels: Batch of integer labels associated with embeddings. shape: (batch_size,)\n",
    "\n",
    "    Returns:\n",
    "      Scalar loss value.\n",
    "    \"\"\"\n",
    "    # step 1 - convert to tensor format\n",
    "    distance_matrix = torch.tensor(distance_matrix)\n",
    "    labels = torch.tensor(list(labels.values()))\n",
    "\n",
    "\n",
    "    # step 2 - compute loss values for all triplets by applying broadcasting to distance matrix\n",
    "\n",
    "    # shape: (batch_size, batch_size, 1)\n",
    "    anchor_positive_dists = distance_matrix.unsqueeze(2)\n",
    "    # shape: (batch_size, 1, batch_size)\n",
    "    anchor_negative_dists = distance_matrix.unsqueeze(1)\n",
    "    # get loss values for all possible n^3 triplets\n",
    "    # shape: (batch_size, batch_size, batch_size)\n",
    "    triplet_loss = anchor_negative_dists - anchor_positive_dists + self.margin\n",
    "    ###print('tl0',triplet_loss)\n",
    "\n",
    "    # step 3 - filter out invalid or easy triplets by setting their loss values to 0\n",
    "\n",
    "    # shape: (batch_size, batch_size, batch_size)\n",
    "    mask = get_triplet_mask(labels)\n",
    "    ###print('mask', mask)\n",
    "    triplet_loss *= mask\n",
    "    ###print(triplet_loss)\n",
    "    ###print('tl1:', triplet_loss)\n",
    "    # easy triplets have negative loss values\n",
    "    \n",
    "    triplet_loss = self.custom(triplet_loss)\n",
    "    ###print(triplet_loss)\n",
    "    #triplet_loss = F.relu(triplet_loss)\n",
    "\n",
    "    # step 4 - compute scalar loss value by averaging positive losses\n",
    "    \n",
    "    triLossNonZero = (triplet_loss != 0).nonzero(as_tuple=True)\n",
    "    labelTorchUnique = torch.unique(labels, return_counts=True)\n",
    "    \n",
    "    nonZero = len(triLossNonZero[0])\n",
    "    triLossSum = []\n",
    "    for i in range(nonZero):\n",
    "        #Identify L_a --> In Class\n",
    "        t1 = triLossNonZero[0][i]\n",
    "        labelIn = labels[t1]\n",
    "        positionIn = int((labelTorchUnique[0] == labelIn).nonzero(as_tuple=False))\n",
    "        countIn = labelTorchUnique[1][positionIn]\n",
    "\n",
    "        #Identify L_b --> Out Class\n",
    "        t3 = triLossNonZero[2][i]\n",
    "        labelOut = labels[t3]\n",
    "        positionOut = int((labelTorchUnique[0] == labelOut).nonzero(as_tuple=False))\n",
    "        countOut = labelTorchUnique[1][positionOut]\n",
    "\n",
    "        #Calculate loss\n",
    "        value = (1/countIn)*(1/countIn)*(1/countOut)  \n",
    "        ###print(countIn)\n",
    "        ###print(countOut)\n",
    "        triLossSum.append(value)\n",
    "    \n",
    "    #finally divide by |A|^2-|A|\n",
    "    A = len(labelTorchUnique[0])  \n",
    "    lossValue = sum(triLossSum) / (A*A-A)\n",
    "        \n",
    "    #OLD\n",
    "    #E_triplet = (1 / (A^2 - A)) *\n",
    "    #num_positive_losses = (triplet_loss > eps).float().sum()\n",
    "    #print(num_positive_losses)\n",
    "    #print(triplet_loss.sum())\n",
    "    #triplet_loss = triplet_loss.sum() / (num_positive_losses + eps)\n",
    "    \n",
    "\n",
    "    return lossValue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f12a92e",
   "metadata": {},
   "source": [
    "## Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26715870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def Silhouette(distMatrix, labelDict):\n",
    "    labelDictList = list(labelDict.values())\n",
    "    return metrics.silhouette_score(distMatrix, labelDictList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f908a1",
   "metadata": {},
   "source": [
    "### Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc3642f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ast\n",
    "#\n",
    "##Calculate Levenshtein Distances\n",
    "#logVar[\"activity\"] = logVar[\"activity\"].apply(lambda x: ast.literal_eval(x))\n",
    "#logVar[\"c:n_chr\"] = logVar[\"activity\"].apply(lambda x: [chr(int(i)) for i in x])\n",
    "#logVar[\"strings\"] = logVar[\"c:n_chr\"].apply(lambda x: ''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3b767d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.9400000000000001\n",
      "P@10: 0.7576666666666667\n",
      "Tri:  tensor(0.5452)\n",
      "Sil:  -0.06365998076755451\n"
     ]
    }
   ],
   "source": [
    "#Levenshtein Distance\n",
    "#from Levenshtein import distance\n",
    "\n",
    "lev_dis = matrix_calc(logVar[\"strings\"],distance)\n",
    "results(lev_dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d769e7",
   "metadata": {},
   "source": [
    "### Normalized Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecb15751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.9466666666666667\n",
      "P@10: 0.7893333333333334\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m         dist_matrix[j,i] \u001b[38;5;241m=\u001b[39m dist_matrix[i,j]       \u001b[38;5;66;03m# for the symmetric part, no computation\u001b[39;00m\n\u001b[0;32m     11\u001b[0m lev_dis_norm \u001b[38;5;241m=\u001b[39m dist_matrix\n\u001b[1;32m---> 12\u001b[0m \u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlev_dis_norm\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 6\u001b[0m, in \u001b[0;36mresults\u001b[1;34m(DistMatrix)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP@10: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(PrecisionAtK(DistMatrix, labelDict1, \u001b[38;5;241m10\u001b[39m)))\n\u001b[0;32m      5\u001b[0m triplet \u001b[38;5;241m=\u001b[39m BatchAllTtripletLoss()\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTri:  \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mtriplet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDistMatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabelDict1\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSil:  \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(Silhouette(DistMatrix, labelDict1)))\n",
      "Cell \u001b[1;32mIn[29], line 137\u001b[0m, in \u001b[0;36mBatchAllTtripletLoss.forward\u001b[1;34m(self, distance_matrix, labels)\u001b[0m\n\u001b[0;32m    134\u001b[0m countOut \u001b[38;5;241m=\u001b[39m labelTorchUnique[\u001b[38;5;241m1\u001b[39m][positionOut]\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m#Calculate loss\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m value \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mcountIn)\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mcountIn)\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mcountOut\u001b[49m)  \n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m###print(countIn)\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m###print(countOut)\u001b[39;00m\n\u001b[0;32m    140\u001b[0m triLossSum\u001b[38;5;241m.\u001b[39mappend(value)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pm4py\\lib\\site-packages\\torch\\_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pm4py\\lib\\site-packages\\torch\\_tensor.py:852\u001b[0m, in \u001b[0;36mTensor.__rdiv__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rdiv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreciprocal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "List = logVar[\"strings\"]\n",
    "\n",
    "n = len(List)\n",
    "dist_matrix = np.zeros((n,n))    # initialize distance matrix to a square of zeros\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = distance(List[i], List[j]) / max(len(List[i]),len(List[j]))\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]       # for the symmetric part, no computation\n",
    "\n",
    "lev_dis_norm = dist_matrix\n",
    "results(lev_dis_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e767dec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.89\n",
      "P@10: 0.7073333333333333\n",
      "Tri:  tensor(0.3958)\n",
      "Sil:  0.02682988463883863\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Matrix = lev_dis_norm\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7dd7ae",
   "metadata": {},
   "source": [
    "### Cosine based on 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbe30ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 1-gram\n",
    "\n",
    "def createVector(charList):\n",
    "    #dtype = [('structure', 'S10'), ('relfrequ', float)]\n",
    "    arrayList = np.array(charList)\n",
    "    unique, counts = np.unique(arrayList, return_counts=True)\n",
    "    #calculate relative frequency\n",
    "    relFrequList = np.array((unique, counts)).T\n",
    "    uniqueList = list(unique)\n",
    "    return relFrequList[relFrequList[:, 0].argsort()]\n",
    "    #check completeness\n",
    "    #if 'tree' not in uniqueList:\n",
    "        #relFrequList = np.append(relFrequList, np.array([['tree', 0]]), axis=0)\n",
    "        #print(relFrequList)\n",
    "\n",
    "        \n",
    "#Change data format from string to list of unique characters\n",
    "logVar[\"1-gram\"] = logVar[\"c:n_chr\"].apply(lambda x: createVector(tuple(x)))\n",
    "#logVar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2556cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignArrays(array1, array2):\n",
    "    commonSet = set(array1[:,0]).union(array2[:,0])\n",
    "    \n",
    "    for i in commonSet:\n",
    "        if i not in array1[:,0]:\n",
    "            array1 = np.append(array1, np.array([[i, '0']]), axis=0)\n",
    "        if i not in array2[:,0]:\n",
    "            array2 = np.append(array2, np.array([[i, '0']]), axis=0)\n",
    "    return array1[array1[:, 0].argsort()], array2[array2[:, 0].argsort()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51bc8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot embedding\n",
    "'''\n",
    "def alignArrays_OneHotEmbedding(array1, array2):\n",
    "    \n",
    "    for i in range(len(array1)):\n",
    "        if int(array1[:,1][i]) > 1:\n",
    "            array1[:,1][i] = 1\n",
    "    \n",
    "    for i in range(len(array2)):\n",
    "        if int(array2[:,1][i]) > 1:\n",
    "            array2[:,1][i] = 1\n",
    "               \n",
    "    commonSet = set(array1[:,0]).union(array2[:,0])\n",
    "    #print(commonSet)\n",
    "        \n",
    "    for i in commonSet:\n",
    "        if i not in array1[:,0]:\n",
    "            array1 = np.append(array1, np.array([[i, '0']]), axis=0)\n",
    "        if i not in array2[:,0]:\n",
    "            array2 = np.append(array2, np.array([[i, '0']]), axis=0)\n",
    "    return array1[array1[:, 0].argsort()], array2[array2[:, 0].argsort()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2a7a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def cosineDist(frequVector1, frequVector2):\n",
    "    Vector1, Vector2 = alignArrays(frequVector1, frequVector2)\n",
    "    a = Vector1[:,1].astype(int)\n",
    "    b = Vector2[:,1].astype(int)\n",
    "    dist_matrix = distance.cosine(a, b)\n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on 1-gram\n",
    "\n",
    "cos1_dis = matrix_calc(logVar[\"1-gram\"],cosineDist)\n",
    "results(cos1_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63a2bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on 1-gram\n",
    "'''\n",
    "listVec = logVar[\"1-gram\"]\n",
    "\n",
    "n = len(listVec)\n",
    "dist_matrix = np.zeros((n,n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = cosineDist(listVec[i], listVec[j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]  \n",
    "        \n",
    "cos1_dis = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c40d84e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.65\n",
      "P@10: 0.5830000000000001\n",
      "Tri:  tensor(0.4027)\n",
      "Sil:  0.07251093635240966\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Matrix = cos1_dis\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaed8c6",
   "metadata": {},
   "source": [
    "### Cosine based on 2-gram and 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58972a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change data format from string to list of unique characters\n",
    "#logVar[\"charList\"] = logVar[\"trace_variant\"].apply(lambda x: list(x))\n",
    "#logVar\n",
    "\n",
    "def df_list(list_of_char):\n",
    "    extList = list_of_char.copy()\n",
    "    extList.insert(0, '*') \n",
    "    extList.append('$')\n",
    "    list_new = []\n",
    "    for i in range(len(extList)):\n",
    "        new = ''.join(extList[i:i+2])\n",
    "        list_new.append(new)\n",
    "    del list_new[-1]\n",
    "    return list_new\n",
    "\n",
    "#Change data format from string to list of unique characters\n",
    "logVar[\"dfList\"] = logVar[\"c:n_chr\"].apply(lambda x: df_list(x))\n",
    "#logVar\n",
    "\n",
    "logVar[\"2-gram\"] = logVar[\"dfList\"].apply(lambda x: createVector(x))\n",
    "#logVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b052a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on 2-gram\n",
    "\n",
    "cos2_dis = matrix_calc(logVar[\"2-gram\"],cosineDist)\n",
    "results(cos2_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 3-gram\n",
    "\n",
    "#Change data format from string to list of unique characters\n",
    "logVar[\"charList\"] = logVar[\"c:n_chr\"].apply(lambda x: list(x))\n",
    "\n",
    "def df_list2(list_of_char):\n",
    "    extList = list_of_char.copy()\n",
    "    extList.insert(0, '*') \n",
    "    extList.append('$')\n",
    "    list_new = []\n",
    "    for i in range(len(extList) - 1):\n",
    "        new = ''.join(extList[i:i+3])\n",
    "        list_new.append(new)\n",
    "    del list_new[-1]\n",
    "    return list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logVar[\"dfList2\"] = logVar[\"charList\"].apply(lambda x: df_list2(x))\n",
    "logVar[\"3-gram\"] = logVar[\"dfList2\"].apply(lambda x: createVector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2474ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on 3-gram\n",
    "\n",
    "cos3_dis = matrix_calc(logVar[\"3-gram\"],cosineDist)\n",
    "results(cos3_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75dd41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08af481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on 2-gram\n",
    "'''\n",
    "listVec = logVar[\"2-gram\"]\n",
    "\n",
    "n = len(listVec)\n",
    "dist_matrix = np.zeros((n,n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = cosineDist(listVec[i], listVec[j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]  \n",
    "        \n",
    "cos2_dis = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c11b475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.98\n",
      "P@10: 0.9480000000000001\n",
      "Tri:  tensor(0.3969)\n",
      "Sil:  0.008759672572068024\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Matrix = cos2_dis\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3ea73c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.98\n",
      "P@10: 0.9369999999999999\n",
      "Tri:  tensor(0.4109)\n",
      "Sil:  0.015884217428528864\n"
     ]
    }
   ],
   "source": [
    "#Aggregation\n",
    "'''\n",
    "aggregate = cos1_dis + cos2_dis\n",
    "\n",
    "Matrix = aggregate\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b870cd",
   "metadata": {},
   "source": [
    "## Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7fc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance\n",
    "# see https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy\n",
    "\n",
    "def euclidDist(frequVector1, frequVector2):\n",
    "    Vector1, Vector2 = alignArrays(frequVector1, frequVector2)\n",
    "    a = Vector1[:,1].astype(float)\n",
    "    b = Vector2[:,1].astype(float)\n",
    "    euclidean_dist = np.linalg.norm(a-b)\n",
    "    return euclidean_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a2aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean distance based on 1-gram\n",
    "\n",
    "euc1_dis = matrix_calc(logVar[\"1-gram\"],euclidDist)\n",
    "results(euc1_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b36c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean distance based on 2-gram\n",
    "\n",
    "euc2_dis = matrix_calc(logVar[\"2-gram\"],euclidDist)\n",
    "results(euc2_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2deb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean distance based on 3-gram\n",
    "\n",
    "euc3_dis = matrix_calc(logVar[\"3-gram\"],euclidDist)\n",
    "results(euc3_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregation\n",
    "\n",
    "agg_euc = euc1_dis + euc2_dis\n",
    "results(agg_euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6378a9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efaef19c",
   "metadata": {},
   "source": [
    "### Jaccard based on 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "feb39b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance based on activity type\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    s1, s2 = set(list1), set(list2)\n",
    "    return 1 - len(s1 & s2) / len(s1 | s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba79bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jaccard based on 1-gram\n",
    "Jacc1_dis = matrix_calc(logVar[\"charList\"],jaccard_similarity)\n",
    "results(Jacc1_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jaccard based on 2-gram\n",
    "Jacc2_dis = matrix_calc(logVar[\"dfList\"],jaccard_similarity)\n",
    "results(Jacc2_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97242b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jaccard based on 3-gram\n",
    "Jacc3_dis = matrix_calc(logVar[\"dfList2\"],jaccard_similarity)\n",
    "results(Jacc3_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d616d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregation\n",
    "\n",
    "agg_jacc1 = Jacc1_dis + Jacc2_dis\n",
    "results(agg_jacc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850894ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_jacc2 = Jacc1_dis + Jacc2_dis + Jacc3_dis\n",
    "results(agg_jacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe6191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17049e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ListChar = list(logVar[\"activity\"])\n",
    "\n",
    "n = len(ListChar)\n",
    "dist_matrix = np.zeros((n,n))    # initialize distance matrix to a square of zeros\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = jaccard_similarity(ListChar[i], ListChar[j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]       # for the symmetric part, no computation\n",
    "        \n",
    "jacc1_dis = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8606da9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.3333333333333333\n",
      "P@10: 0.3333333333333333\n",
      "Tri:  tensor(0.2429)\n",
      "Sil:  -0.009999999999999969\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Matrix = jacc1_dis\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baad37ec",
   "metadata": {},
   "source": [
    "### Jaccard based on 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "664a9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance based on adjacency relations\n",
    "\n",
    "#Create list of directly follow relations\n",
    "'''\n",
    "def df_list(list_of_char):\n",
    "    extList = list_of_char.copy()\n",
    "    extList.insert(0, '*') \n",
    "    extList.append('$')\n",
    "    list_new = []\n",
    "    for i in range(len(extList)):\n",
    "        new = ''.join(extList[i:i+2])\n",
    "        list_new.append(new)\n",
    "    del list_new[-1]\n",
    "    return list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c8c2746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change data format from string to list of unique characters\n",
    "#logVar[\"dfList\"] = logVar[\"c:n_chr\"].apply(lambda x: df_list(x))\n",
    "#logVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da1ba214",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ListChar = list(logVar[\"dfList\"])\n",
    "\n",
    "n = len(ListChar)\n",
    "dist_matrix = np.zeros((n,n))    # initialize distance matrix to a square of zeros\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = jaccard_similarity(ListChar[i], ListChar[j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]       # for the symmetric part, no computation\n",
    "        \n",
    "jacc2_dis = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b14857d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.98\n",
      "P@10: 0.9480000000000001\n",
      "Tri:  tensor(0.3969)\n",
      "Sil:  0.021537992116025678\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Matrix = jacc2_dis\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4a8c4136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.98\n",
      "P@10: 0.9480000000000001\n",
      "Tri:  tensor(0.3969)\n",
      "Sil:  0.004350052766413874\n"
     ]
    }
   ],
   "source": [
    "#Aggregation\n",
    "'''\n",
    "aggregate = jacc1_dis + jacc2_dis\n",
    "\n",
    "Matrix = aggregate\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8982bc",
   "metadata": {},
   "source": [
    "## Graph based measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "553dcf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now consider edge types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26f94a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. transfer strings (string numbers) to integers --> HERE we need a new encoding!\n",
    "\n",
    "def intEncoder(character_List):\n",
    "    return [np.where(np.array(list(dict.fromkeys(character_List)))==e)[0][0]for e in character_List]\n",
    "\n",
    "logVar[\"intList\"] = logVar[\"activity\"].apply(lambda x: intEncoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "26a1b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. transfer intList to int_tupleList\n",
    "\n",
    "#Create tuple lists\n",
    "def tuple_list(list_of_encodedActivities):\n",
    "    #list.insert(0, '*')\n",
    "    #list.append('*')\n",
    "    list_new = []\n",
    "    last_element = list_of_encodedActivities[-1]\n",
    "    for i in range(len(list_of_encodedActivities)):\n",
    "        new = tuple(list_of_encodedActivities[i:i+2])\n",
    "        list_new.append(new)\n",
    "    del list_new[-1]\n",
    "    if list_of_encodedActivities.count(last_element) == 1: #check wether last activity in trace has some adjancency relation\n",
    "        list_new.append((last_element,)) ### NOT Correct\n",
    "    return list_new\n",
    "\n",
    "#q = [0,0,0,0,1,1,2,3,4,5,3,2,4,0,5,6]\n",
    "#tuple_list(q)\n",
    "\n",
    "logVar[\"int_tupleList\"] = logVar[\"intList\"].apply(lambda x: tuple_list(x))\n",
    "#logVar[\"int_tupleList\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4db1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. generate Adjacency List\n",
    "\n",
    "def adj_list(list_of_tuples):\n",
    "    adj_list_new = {}\n",
    "    try:\n",
    "        for node1, node2 in list_of_tuples:\n",
    "            #print(node1, node2)\n",
    "            if node1 not in adj_list_new:\n",
    "                newlist = []\n",
    "                newlist.append(node2)\n",
    "                adj_list_new[node1] = newlist\n",
    "                #print(adj_list3)\n",
    "        \n",
    "            else:\n",
    "                if node2 not in adj_list_new[node1]:\n",
    "                    #mylist.extend(adj_list3[node1])\n",
    "                    adj_list_new[node1].append(node2)\n",
    "                    #print(adj_list3)\n",
    "                    #adj_list3[node1] = mylist\n",
    "    \n",
    "    #in case activity has no adjacent activity - only possible for last activity --> tuple: (lastAct,)\n",
    "    except ValueError as ve:\n",
    "        lastValue = list_of_tuples[-1][0] \n",
    "        adj_list_new[lastValue] = list()\n",
    "    return list(adj_list_new.values())\n",
    "\n",
    "#q = [0,0,0,0,1,1,2,3,4,5,3,2,4,0,5,6]\n",
    "#l = tuple_list(q)\n",
    "#adj_list(l)\n",
    "\n",
    "logVar[\"int_adjList\"] = logVar[\"int_tupleList\"].apply(lambda x: adj_list(x))\n",
    "#logVar[\"int_adjList\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5433d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now considering length\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "def bfs_4(graph, start, end):\n",
    "    \n",
    "    graph = {v: k for v, k in enumerate(graph)}\n",
    "    #print(start, end)\n",
    "    queue = deque([(start, 0)])\n",
    "    seen = set()\n",
    "    while queue:\n",
    "        #print(queue)\n",
    "        node, distance = queue.popleft()\n",
    "        #if not node:\n",
    "            #print(start, end, queue)\n",
    "            #print(\"GRAPH LIST\", graph)\n",
    "        if node in seen:\n",
    "            continue\n",
    "        seen.add(node)\n",
    "        if node == end:\n",
    "            return distance \n",
    "        for adjacent in graph.get(node, []):\n",
    "            queue.append((adjacent, distance + 1))\n",
    "        \n",
    "#x = {0: [0, 1], 1: [2, 1, 0, int], 2:[2], [3: [1, 5, 3, 7], 4: [3], 5: [6, 5], 6: [1, 7], 7: [8, 9, 7], 8: [5, 8, 10], 9: [3]}\n",
    "#y = [[0, 1, 5], [1, 2], [3, 4], [4, 2], [5, 0], [3, 6], []]\n",
    "#bfs_4(y, 1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01800b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "def reverse_graph(graph):\n",
    "    reversed_graph = defaultdict(list)\n",
    "    for node in graph:\n",
    "        for neighbor in graph[node]:\n",
    "            reversed_graph[neighbor].append(node)\n",
    "    return reversed_graph\n",
    "\n",
    "\n",
    "def bfs_5(graph, start, end):\n",
    "    queue = deque([(start, 0)])\n",
    "    seen = set()\n",
    "    visited = {}\n",
    "    while queue:\n",
    "        node, distance = queue.popleft()\n",
    "        if node in seen:\n",
    "            continue\n",
    "        seen.add(node)\n",
    "        if node == end: # maybe quicker if adjacent directly checked\n",
    "            return visited\n",
    "        for adjacent in graph.get(node, []):\n",
    "            queue.append((adjacent, distance + 1))\n",
    "            if adjacent not in visited:\n",
    "                visited.update({adjacent:distance})\n",
    "\n",
    "            \n",
    "def common_ancestors(graph, node1, node2): \n",
    "    #remove cross type edge between node1 and node2\n",
    "    graph[node1].remove(node2) #maybe issue, if graph is changed and not copy of graph?\n",
    "    graph = {v: k for v, k in enumerate(graph)}\n",
    "    graphReverse = reverse_graph(graph)\n",
    "    setNode1 = bfs_5(graphReverse, node1, 0)\n",
    "    setNode2 = bfs_5(graphReverse, node2, 0)\n",
    "    if next((a for a in list(setNode1) if a in list(setNode2)), None) == None:\n",
    "        firstCommonAnces = next((a for a in list(setNode2) if a in list(setNode1)), None)\n",
    "    else:\n",
    "        firstCommonAnces = next((a for a in list(setNode1) if a in list(setNode2)), 0)\n",
    "    \n",
    "    #uses a hash map to identify the first common ancestor in both lists\n",
    "    #looks for the first common ancestor in setNode1, which can also be found in setNode2 \n",
    "    #--> this might not be the closest distance between setNode1 and setNode2\n",
    "    #--> e.g., for x= [0,1,3,7,5,6] and y= [4,5,7,8,3] 7 might be closest ancestor, although algo detects 3 !\n",
    "    #distance = setNode1[firstCommonAnces] + setNode2[firstCommonAnces]\n",
    "    \n",
    "    \n",
    "    if firstCommonAnces != None:   # ISSUE: in some cases the firstCommonAnces cannot be detected!\n",
    "        ancesDistNode1 =  setNode1[firstCommonAnces] + 1 #the edge from node1 to first parent is counted as 0 by algorithm, therefore +1\n",
    "        ancesDistNode2 =  setNode2[firstCommonAnces] + 1\n",
    "        numberSkips = abs(ancesDistNode1 - ancesDistNode2)\n",
    "        numberCross = min(ancesDistNode1, ancesDistNode2)\n",
    "    else:\n",
    "        numberSkips, numberCross = (0,1)\n",
    "    return numberSkips, numberCross\n",
    "    #if all(x in crossType for x in i):\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#graphList = [[1], [2, 4, 1], [3, 2, 1], [], [5, 4], [5, 4, 6], [7], []]\n",
    "#c = [[1, 4], [2], [3], [0, 5], [3, 5], []]\n",
    "#c2 = {v: k for v, k in enumerate(c)}\n",
    "#common_ancestors(c, 4, 5)\n",
    "#reverse_graph(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ebeba241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create List for decoding traces\n",
    "from collections import OrderedDict\n",
    "logVar[\"indexList\"] = logVar[\"activity\"].apply(lambda x: list(OrderedDict.fromkeys(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e36477c",
   "metadata": {},
   "source": [
    "### Cosine Edge Type + length (no df relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d96d6875",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph1:\n",
    "    # instance variables\n",
    "    def __init__(self, graph_list2, indexList):\n",
    "        # v is the number of nodes/vertices\n",
    "        self.time = 0\n",
    "        self.traversal_array = []\n",
    "        self.structural_array = [['sequ', 1]]\n",
    "        #self.structural_array = []\n",
    "        self.graph_list = graph_list2\n",
    "        self.v = len(graph_list2)\n",
    "        self.indexList = indexList\n",
    "\n",
    "    # function for dfs\n",
    "    def dfs(self):\n",
    "        self.start_time = [-1]*self.v\n",
    "        self.end_time = [-1]*self.v\n",
    " \n",
    "        for node in range(self.v):\n",
    "            if self.start_time[node] == -1:\n",
    "                self.traverse_dfs(node)\n",
    "                \n",
    "        return np.array(self.structural_array)\n",
    "        #print()\n",
    "        #print(\"DFS Traversal: \", self.traversal_array)\n",
    "        #print()\n",
    " \n",
    "    def traverse_dfs(self, node):\n",
    "        self.traversal_array.append(node)\n",
    "        # get the starting time\n",
    "        self.start_time[node] = self.time\n",
    "        self.time += 1\n",
    "        # traverse through the neighbours\n",
    "        for neighbour in self.graph_list[node]:\n",
    "\n",
    "            # when the neighbor was not yet visited\n",
    "            if self.start_time[neighbour] == -1:                \n",
    "                self.structural_array[0][1] += 0\n",
    "                self.traverse_dfs(neighbour)\n",
    "                \n",
    "            # otherwise when the neighbour's visit is still ongoing:\n",
    "            elif self.end_time[neighbour] == -1:\n",
    "                if node == neighbour:\n",
    "                    self.structural_array.append(['1back ',1])\n",
    "                    #self.structural_array.append(['back ',1])\n",
    "                    #self.structural_array.append([str(1)+'b'])\n",
    "                \n",
    "                elif node in self.graph_list[neighbour]:\n",
    "                    self.structural_array.append(['2back ',2])\n",
    "                    #self.structural_array.append(['back ',2])\n",
    "                    #self.structural_array.append(str(2)+'b')\n",
    "                    \n",
    "                else:\n",
    "                    x = bfs_4(self.graph_list, neighbour, node)\n",
    "                    self.structural_array.append([str(x+1)+'back ',x+1])\n",
    "                    #self.structural_array.append(['back ',x+1])\n",
    "                    #self.structural_array.append(str(x+1)+'b')\n",
    "                \n",
    "            # otherwise when the neighbour's visit started before the current node's visit:\n",
    "            elif self.start_time[node] < self.start_time[neighbour]:\n",
    "                graph_list_copy = copy.deepcopy(self.graph_list)\n",
    "                graph_list_copy[node].remove(neighbour)\n",
    "                y = bfs_4(graph_list_copy, node, neighbour)\n",
    "                self.structural_array.append([str(y-1)+'forward ',y-1])\n",
    "                #self.structural_array.append(['forward ' ,y-1])\n",
    "                #self.structural_array.extend((y-1)*['forward']) # -1 to exclude one edge: (A:B,C;B:C;C:[]) ...the dist A --> C is 2 without forward edge, but we are skipping only one activity\n",
    "                #self.structural_array.append(str(y-1)+'f')\n",
    "                \n",
    "            else:\n",
    "                #Possibly first check, whether two nodes connected by cross-type have identical parent\n",
    "                numberSkips, numberCross = common_ancestors(self.graph_list, node, neighbour)\n",
    "                #self.structural_array.append(['forward ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]),numberSkips])\n",
    "                self.structural_array.append([str(numberCross)+'cross ',numberCross])\n",
    "                #self.structural_array.append(['cross ' ,numberCross])\n",
    "                #self.structural_array.append(str(numberSkips)+'f')\n",
    "                #self.structural_array.append(str(numberCross)+'c')\n",
    "    \n",
    "        # Indentation corrected:\n",
    "        self.end_time[node] = self.time\n",
    "        self.time += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a606aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def transform_list_of_pairs(pairs):\n",
    "    return [pair[0] for pair in pairs]\n",
    "\n",
    "\n",
    "\n",
    "def count_entries(input_list):\n",
    "    # Count the occurrences of each unique entry in the list\n",
    "    counter = Counter(input_list)\n",
    "    \n",
    "    # Create a NumPy array from the counter dictionary\n",
    "    result = np.array([[key, count] for key, count in counter.items()], dtype=object)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "#input_list = ['sequ', '2back', '2back']\n",
    "#result = count_entries(input_list)\n",
    "#print(result)\n",
    "\n",
    "logVar[\"int_strucLengthList2\"] = logVar.apply(lambda x: Graph1(x.int_adjList, x.indexList).dfs(), axis =1)\n",
    "logVar[\"relFrequVec1\"] = logVar[\"int_strucLengthList2\"].apply(lambda x: transform_list_of_pairs(x))\n",
    "logVar[\"relFrequVec1\"] = logVar[\"relFrequVec1\"].apply(lambda x: count_entries(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13649a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on edge types\n",
    "cos_graph_dis = matrix_calc(logVar[\"relFrequVec1\"],cosineDist)\n",
    "results(cos_graph_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f449e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine distance based on edge types\n",
    "agg_cos = cos1_dis + cos2_dis + cos_graph_dis\n",
    "results(agg_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20278ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "12d0c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "logVar[\"int_strucLengthList2\"] = logVar.apply(lambda x: Graph1(x.int_adjList, x.indexList).dfs(), axis =1)\n",
    "\n",
    "logVar[\"relFrequVec2\"] = logVar[\"int_strucLengthList2\"].apply(lambda x: pd.DataFrame(x, columns=['String', 'Value']))\n",
    "logVar[\"relFrequVec2\"] = logVar[\"relFrequVec2\"].apply(lambda x: x.groupby('String', as_index=False)['Value'].sum())\n",
    "logVar[\"relFrequVec2\"] = logVar[\"relFrequVec2\"].apply(lambda x: x.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "23c38dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logVar[\"int_strucLengthList2\"] = logVar[\"int_adjList\"].apply(lambda x: Graph3(x).dfs())\n",
    "#logVar[\"relFrequVec3\"] = logVar[\"int_strucLengthList2\"].apply(lambda x: createVector(x))\n",
    "'''\n",
    "\n",
    "listVec = list(logVar[\"relFrequVec2\"])\n",
    "\n",
    "n = len(listVec)\n",
    "dist_matrix = np.zeros((n,n))    # initialize distance matrix to a square of zeros\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = cosineDist(listVec[i], listVec[j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]       # for the symmetric part, no computation\n",
    "        \n",
    "cos_graph_dis1 = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd16bc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.9266666666666667\n",
      "P@10: 0.9073333333333333\n",
      "Tri:  tensor(0.6505)\n",
      "Sil:  0.32187699305855083\n"
     ]
    }
   ],
   "source": [
    "#No df relations\n",
    "'''\n",
    "Matrix = cos_graph_dis1\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe8de811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.88\n",
      "P@10: 0.906\n",
      "Tri:  tensor(0.7019)\n",
      "Sil:  0.23814636943372902\n"
     ]
    }
   ],
   "source": [
    "#Aggregation\n",
    "'''\n",
    "aggregate = cos1_dis + cos2_dis + cos_graph_dis1\n",
    "\n",
    "Matrix = aggregate\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f88c69e",
   "metadata": {},
   "source": [
    "### Jaccard Edge Type and length + df relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bd8352d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph2:\n",
    "    # instance variables\n",
    "    def __init__(self, graph_list2, indexList):\n",
    "        # v is the number of nodes/vertices\n",
    "        self.time = 0\n",
    "        self.traversal_array = []\n",
    "        self.structural_array = []\n",
    "        #self.structural_array = []\n",
    "        self.graph_list = graph_list2\n",
    "        self.v = len(graph_list2)\n",
    "        self.indexList = indexList\n",
    "\n",
    "    # function for dfs\n",
    "    def dfs(self):\n",
    "        self.start_time = [-1]*self.v\n",
    "        self.end_time = [-1]*self.v\n",
    " \n",
    "        for node in range(self.v):\n",
    "            if self.start_time[node] == -1:\n",
    "                self.traverse_dfs(node)\n",
    "                \n",
    "        return self.structural_array\n",
    "        #print()\n",
    "        #print(\"DFS Traversal: \", self.traversal_array)\n",
    "        #print()\n",
    " \n",
    "    def traverse_dfs(self, node):\n",
    "        self.traversal_array.append(node)\n",
    "        # get the starting time\n",
    "        self.start_time[node] = self.time\n",
    "        self.time += 1\n",
    "        # traverse through the neighbours\n",
    "        for neighbour in self.graph_list[node]:\n",
    "\n",
    "            # when the neighbor was not yet visited\n",
    "            if self.start_time[neighbour] == -1:                \n",
    "                #self.structural_array[0][1] += 0\n",
    "                #self.structural_array.append('tree ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ')\n",
    "                self.structural_array.append('tree')\n",
    "                self.traverse_dfs(neighbour)\n",
    "                \n",
    "            # otherwise when the neighbour's visit is still ongoing:\n",
    "            elif self.end_time[neighbour] == -1:\n",
    "                if node == neighbour:\n",
    "                    self.structural_array.append('back ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ' ' + str(1))\n",
    "                    #self.structural_array.append('back ' + str(1))\n",
    "                    #self.structural_array.append([str(1)+'b'])\n",
    "                \n",
    "                elif node in self.graph_list[neighbour]:\n",
    "                    self.structural_array.append('back ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ' ' + str(2))\n",
    "                    #self.structural_array.append('back ' + str(2))\n",
    "                    #self.structural_array.append(str(2)+'b')\n",
    "                    \n",
    "                else:\n",
    "                    x = bfs_4(self.graph_list, neighbour, node)\n",
    "                    self.structural_array.append('back ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ' ' + str(x+1))\n",
    "                    #self.structural_array.append('back ' + str(x+1))\n",
    "                    #self.structural_array.append(str(x+1)+'b')\n",
    "                \n",
    "            # otherwise when the neighbour's visit started before the current node's visit:\n",
    "            elif self.start_time[node] < self.start_time[neighbour]:\n",
    "                graph_list_copy = copy.deepcopy(self.graph_list)\n",
    "                graph_list_copy[node].remove(neighbour)\n",
    "                y = bfs_4(graph_list_copy, node, neighbour)\n",
    "                self.structural_array.append('forward ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ' ' + str(y-1))\n",
    "                #self.structural_array.append('forward' + str(y-1))\n",
    "                #self.structural_array.extend((y-1)*['forward']) # -1 to exclude one edge: (A:B,C;B:C;C:[]) ...the dist A --> C is 2 without forward edge, but we are skipping only one activity\n",
    "                #self.structural_array.append(str(y-1)+'f')\n",
    "                \n",
    "            else:\n",
    "                #Possibly first check, whether two nodes connected by cross-type have identical parent\n",
    "                numberSkips, numberCross = common_ancestors(self.graph_list, node, neighbour)\n",
    "                #self.structural_array.append('forward ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ' ' + str(numberSkips))\n",
    "                self.structural_array.append('cross ' + str(self.indexList[node]) + ' ' + str(self.indexList[neighbour]) + ' ' + str(numberCross))\n",
    "                #self.structural_array.append('cross ' + str(numberCross))\n",
    "                #self.structural_array.append(str(numberSkips)+'f')\n",
    "                #self.structural_array.append(str(numberCross)+'c')\n",
    "    \n",
    "        # Indentation corrected:\n",
    "        self.end_time[node] = self.time\n",
    "        self.time += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7e00cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logVar[\"int_strucLengthList3\"] = logVar.apply(lambda x: Graph2(x.int_adjList, x.indexList).dfs(), axis =1)\n",
    "#logVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcbaddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jacc similarity based on edge types\n",
    "\n",
    "jacc_graph = matrix_calc(logVar[\"int_strucLengthList3\"],jaccard_similarity)\n",
    "results(jacc_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jacc sim based on edge types\n",
    "agg_jacc = Jacc1_dis + Jacc2_dis + jacc_graph\n",
    "results(agg_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e64e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c5aa8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ListChar = list(logVar[\"int_strucLengthList4\"])\n",
    "\n",
    "n = len(ListChar)\n",
    "dist_matrix = np.zeros((n,n))    # initialize distance matrix to a square of zeros\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        dist_matrix[i,j] = jaccard_similarity(ListChar[i], ListChar[j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]       # for the symmetric part, no computation\n",
    "        \n",
    "jacc_graph_dis2 = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6dd94871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.98\n",
      "P@10: 0.919\n",
      "Tri:  tensor(0.5427)\n",
      "Sil:  0.1024140818326163\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Matrix = jacc_graph_dis2\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b725cca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.98\n",
      "P@10: 0.9279999999999999\n",
      "Tri:  tensor(0.5138)\n",
      "Sil:  0.02633120979597622\n"
     ]
    }
   ],
   "source": [
    "#Aggregation\n",
    "'''\n",
    "aggregate = jacc1_dis + jacc2_dis + jacc_graph_dis2\n",
    "\n",
    "Matrix = aggregate\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9115a2c",
   "metadata": {},
   "source": [
    "## Eventually Follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7791748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial distance between strings\n",
    "\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "def distanceSpatial(traceString, char1, char2):\n",
    "    positions_letter1 = [pos for pos, char in enumerate(traceString) if char == char1]\n",
    "    positions_letter2 = [pos for pos, char in enumerate(traceString) if char == char2]\n",
    "    \n",
    "    distList = []\n",
    "    \n",
    "\n",
    "    for i in range(len(positions_letter1)):\n",
    "        for j in range(len(positions_letter2)):\n",
    "            dist = positions_letter2[j] - positions_letter1[i]\n",
    "            if dist > 0:\n",
    "                    #print(dist)\n",
    "                distList.append(dist)\n",
    "                    \n",
    "    \n",
    "    if not distList: #distList.append(0) #in the case the char1 is after char2 asign dist 0, i.e. char2 cannot be reached from char1\n",
    "        return 0\n",
    "    else:\n",
    "        return 1/min(distList)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def commonDistance(trace1, trace2):\n",
    "    \n",
    "    commonSet = set(trace1) & set(trace2)\n",
    "\n",
    "    commonList = list(commonSet)\n",
    "    commonList.sort()\n",
    "    #print(commonList)\n",
    "\n",
    "    n = len(commonSet)\n",
    "    dist_matrix1 = np.zeros((n,n))\n",
    "    dist_matrix2 = np.zeros((n,n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            dist_matrix1[i,j] = distanceSpatial(trace1, commonList[i], commonList[j])\n",
    "        \n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            dist_matrix2[i,j] = distanceSpatial(trace2, commonList[i], commonList[j])\n",
    "    \n",
    "    #print(dist_matrix1, dist_matrix2)\n",
    "    return distance.cosine(dist_matrix1.ravel(), dist_matrix2.ravel())\n",
    "\n",
    "\n",
    "\n",
    "#x = 'ABCDEF'\n",
    "#y = 'ABCDEBCDEBCDEF'\n",
    "#z = 'ABCDEBCDEF'\n",
    "#print(dist_matrix)\n",
    "#distanceSpatial(x, 'A', 'E')\n",
    "#listVec = logVar[\"strings\"]\n",
    "#x= listVec[0]\n",
    "#y= listVec[1]\n",
    "#commonDistance(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab0754",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix_evFollows = matrix_calc(logVar[\"strings\"],commonDistance)\n",
    "dist_matrix_evFollows = np.nan_to_num(dist_matrix_evFollows, nan=0)\n",
    "agg_evFollows = 0.7*dist_matrix_evFollows + 0.3*cos1_dis \n",
    "results(agg_evFollows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8c16a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\la1949\\Anaconda3\\envs\\pm4py\\lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\la1949\\Anaconda3\\envs\\pm4py\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#Calculate cosine similarity based on Spatial distance\n",
    "'''\n",
    "listVec = logVar[\"strings\"]\n",
    "\n",
    "n = len(listVec)\n",
    "dist_matrix = np.zeros((n,n))    # initialize distance matrix to a square of zeros\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        #print(listVec[i], listVec[j])\n",
    "        dist_matrix[i,j] = commonDistance(listVec[i], listVec[j])\n",
    "        #print(dist_matrix[i,j])\n",
    "        dist_matrix[j,i] = dist_matrix[i,j]       # for the symmetric part, no computation\n",
    "        \n",
    "dist_matrix_evFollow = dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2df3ba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:   0.48333333333333334\n",
      "P@10: 0.4073333333333333\n",
      "Tri:  tensor(0.4086)\n",
      "Sil:  0.05811724421139431\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "aggregate = 0.7*dist_matrix_evFollow + 0.3*cos1_dis \n",
    "#Weights 0.7 and 0.3 according to paper: Delias et al. (2015). Supporting healthcare management decisions via robust clustering of event logs. (original source of this metric)\n",
    "\n",
    "Matrix = aggregate\n",
    "\n",
    "print('NN:   ' + str(NearestNeighbor(Matrix, labelDict1)))\n",
    "print('P@10: ' + str(PrecisionAtK(Matrix, labelDict1, 10)))\n",
    "\n",
    "triplet = BatchAllTtripletLoss()\n",
    "print('Tri:  ' + str(triplet.forward(Matrix,labelDict1)))\n",
    "print('Sil:  ' + str(Silhouette(Matrix, labelDict1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617b614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc5150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99163ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03645268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
